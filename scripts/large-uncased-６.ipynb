{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad accumulation!\n",
    "\n",
    "good sentence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAD_POOL = 16\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-uncased-6-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "SENTENCE_FEAURE_USED = ['word_count', 'n_unique', 'n_unique_ratio']\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 3\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190523-112011.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df[SENTENCE_FEAURE_USED].values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 299 ms, total: 5.04 s\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:13<00:00, 132604.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 1.26 s, total: 13.7 s\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:29<00:00, 61610.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.2 s, sys: 1.02 s, total: 27.2 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "        f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, i_fold, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, i_fold, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  159.3\n",
      "epoch start: from start  0.2, from old  159.3\n",
      "start fold 0\n",
      "toxic ratio dev: 0.17379875481128693, val: 0.1735895723104477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpsv4ufcrf\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402756608\n",
      "loaders 1482317312\n",
      "i_epoch 0 start: from start  80.1, from old  159.6\n",
      "epoch_start: 0 1482317312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:21:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  15950.0, from old  239.5\n",
      "after model save: from start  15952.8, from old  16109.3\n",
      "after gc.collect: from start  15955.1, from old  16112.1\n",
      "after gc.collect: from start  15969.0, from old  16114.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  31851.8, from old  16128.4\n",
      "after model save: from start  31853.5, from old  32011.1\n",
      "after gc.collect: from start  31855.8, from old  32012.8\n",
      "after gc.collect: from start  31862.6, from old  32015.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  47743.5, from old  32022.0\n",
      "after model save: from start  47745.4, from old  47902.8\n",
      "after gc.collect: from start  47747.8, from old  47904.8\n",
      "after gc.collect: from start  47754.2, from old  47907.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  63639.1, from old  47913.6\n",
      "after model save: from start  63641.0, from old  63798.4\n",
      "after gc.collect: from start  63643.2, from old  63800.4\n",
      "after gc.collect: from start  63649.7, from old  63802.5\n",
      "after dev all batch: from start  63650.7, from old  63809.0\n",
      "after dev loop 5579910656\n",
      "after all batch gc.collect(): from start  63652.8, from old  63810.0\n",
      "i_epoch 1 start: from start  63652.8, from old  63812.1\n",
      "epoch_start: 1 5579910656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:21:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  79544.3, from old  63812.1\n",
      "after model save: from start  79546.2, from old  79703.7\n",
      "after gc.collect: from start  79548.7, from old  79705.5\n",
      "after gc.collect: from start  79555.2, from old  79708.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  95449.2, from old  79714.5\n",
      "after model save: from start  95451.1, from old  95608.6\n",
      "after gc.collect: from start  95453.2, from old  95610.5\n",
      "after gc.collect: from start  95459.8, from old  95612.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  111357.0, from old  95619.1\n",
      "after model save: from start  111359.2, from old  111516.4\n",
      "after gc.collect: from start  111361.3, from old  111518.5\n",
      "after gc.collect: from start  111367.8, from old  111520.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  127263.9, from old  111527.1\n",
      "after model save: from start  127265.8, from old  127423.2\n",
      "after gc.collect: from start  127267.9, from old  127425.1\n",
      "after gc.collect: from start  127274.5, from old  127427.3\n",
      "after dev all batch: from start  127275.6, from old  127433.8\n",
      "after dev loop 5579910656\n",
      "after all batch gc.collect(): from start  127277.7, from old  127434.9\n",
      "i_epoch 2 start: from start  127277.7, from old  127437.0\n",
      "epoch_start: 2 5579910656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:21:17<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:46<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  143163.0, from old  127437.0\n",
      "after model save: from start  143165.0, from old  143322.3\n",
      "after gc.collect: from start  143167.1, from old  143324.3\n",
      "after gc.collect: from start  143173.7, from old  143326.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  159065.8, from old  143333.0\n",
      "after model save: from start  159067.6, from old  159225.1\n",
      "after gc.collect: from start  159069.8, from old  159227.0\n",
      "after gc.collect: from start  159076.3, from old  159229.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  174967.8, from old  159235.6\n",
      "after model save: from start  174969.7, from old  175127.2\n",
      "after gc.collect: from start  174971.8, from old  175129.0\n",
      "after gc.collect: from start  174978.3, from old  175131.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  190862.3, from old  175137.7\n",
      "after model save: from start  190864.5, from old  191021.6\n",
      "after gc.collect: from start  190866.6, from old  191023.8\n",
      "after gc.collect: from start  190873.2, from old  191026.0\n",
      "after dev all batch: from start  190874.3, from old  191032.5\n",
      "after dev loop 5579910656\n",
      "after all batch gc.collect(): from start  190876.4, from old  191033.6\n",
      "after all folds: from start  190876.4, from old  191035.7\n",
      "after all folds, gc collect: from start  190878.6, from old  191035.7\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7561e+04, 3.1961e+04, 1.6081e+04, 8.1280e+03, 5.6660e+03,\n",
       "        3.3400e+03, 2.5220e+03, 1.7370e+03, 1.0410e+03, 9.7000e+02,\n",
       "        4.3400e+02, 7.8100e+02, 3.3300e+02, 0.0000e+00, 2.9600e+02,\n",
       "        2.5600e+02, 0.0000e+00, 2.1700e+02, 1.7800e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.4200e+02, 0.0000e+00, 0.0000e+00, 1.0500e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([  1. ,   6.1,  11.2,  16.3,  21.4,  26.5,  31.6,  36.7,  41.8,\n",
       "         46.9,  52. ,  57.1,  62.2,  67.3,  72.4,  77.5,  82.6,  87.7,\n",
       "         92.8,  97.9, 103. , 108.1, 113.2, 118.3, 123.4, 128.5, 133.6,\n",
       "        138.7, 143.8, 148.9, 154. , 159.1, 164.2, 169.3, 174.4, 179.5,\n",
       "        184.6, 189.7, 194.8, 199.9, 205. , 210.1, 215.2, 220.3, 225.4,\n",
       "        230.5, 235.6, 240.7, 245.8, 250.9, 256. ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (12,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (12,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD51JREFUeJzt3X+s3Xddx/Hnay0dEQYz9kKg7X4QOqDBH8zrnEFlsoltQ9oYDFl1ImShBh3+YCEOIQMHf4hTQJIhlIgIpisFE3IjJSXicIRQsjsnk3YZuZT9aIfpBcYCmbAV3v5xvvMeL+3ud/ece2/bz/ORNDvfcz73nnc+aZ/33O/5sVQVkqQz31krPYAkaXkYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfDUlyWVJjvRYd0+SK5ZjJmm5GHxJaoTBl6RGGHydlpL8WZJPzLvub5O8N8lrktyV5LtJDif5/RHv6+wk70nyQPfnPUnO7m5bm+RfknwnybeTfD7JWUMzHu3muDvJ5aPMIY3K4Ot0tQfYmuQcgCSrgFcCu4FjwMuBpwGvAd6d5OIR7uvNwKXAzwE/C1wCvKW77VrgCDABPBP4c6CSPA+4BviFqjoH+A3gnhFmkEZm8HVaqqp7gf8AfrO76qXAw1V1oKo+VVVfq4F/Bz4D/MoId/c7wA1VdayqZoG/AH63u+1R4FnA+VX1aFV9vgafSPhD4GxgU5InVdU9VfW1EWaQRmbwdTrbDezoLv92d0ySLUkOdKdYvgNsBdaOcD/PBu4dOr63uw7gRmAG+Ex3+ug6gKqaAf4EeBtwLMmeJM9GWkEGX6ezjwOXJVnP4JH+7u7c+j8Dfw08s6rOBfYBGeF+HgDOHzo+r7uOqvpuVV1bVc8BtgFveOxcfVXtrqpf7r62gHeOMIM0MoOv01Z3euVzwD8AX6+qu4A1DE6lzALHk2wBXjbiXd0MvCXJRJK1wPXAPwEkeXmS5yYJ8BCDUzk/SvK8JC/tfgB9H/gf4EcjziGNxODrdLcbuKL7L1X1XeCPgL3AgwxO9UyNeB/vAKaBO4H/YvDcwTu62zYC/wp8D/gi8L6quoXBD52/BL4J/DfwDOBNI84hjST+H68kqQ0LPsJP8qEkx5J85SS3p3vt80ySO0d8+ZskaYn0OaXzYWDz49y+hcGvtRuBncDfjT6WtLSSnJfkeyf5c95KzycthdULLaiqW5Nc8DhLtgMf6V57fCDJuUmeVVXfGNOM0thV1X3AU1d6Dmk5LRj8HtYB9w8dH+mu+7HgJ9nJ4LcAnvKUp/z885///DHcvSS14/bbb/9mVU0s5mvHEfzeqmoXsAtgcnKypqenl/PuJem0l+TehVed2DhelnkU2DB0vL67TpJ0ChlH8KeAV3Wv1rkUeMjz95J06lnwlE6Sm4HLgLXd/ynorcCTAKrq/Qzetr6VweeJPMzg0wklSaeYPq/S2bHA7QX84dgmkiQtCT9aQZIaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5IaYfAlqREGX5Ia0Sv4STYnuTvJTJLrTnD7eUluSXJHkjuTbB3/qJKkUSwY/CSrgJuALcAmYEeSTfOWvQXYW1UvAq4E3jfuQSVJo+nzCP8SYKaqDlfVI8AeYPu8NQU8rbv8dOCB8Y0oSRqHPsFfB9w/dHyku27Y24CrkhwB9gGvP9E3SrIzyXSS6dnZ2UWMK0larHE9absD+HBVrQe2Ah9N8mPfu6p2VdVkVU1OTEyM6a4lSX30Cf5RYMPQ8fruumFXA3sBquqLwJOBteMYUJI0Hn2CfxuwMcmFSdYweFJ2at6a+4DLAZK8gEHwPWcjSaeQBYNfVceBa4D9wF0MXo1zMMkNSbZ1y64FXpvky8DNwKurqpZqaEnSE7e6z6Kq2sfgydjh664funwIePF4R5MkjZPvtJWkRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWpEr+An2Zzk7iQzSa47yZpXJjmU5GCS3eMdU5I0qtULLUiyCrgJ+HXgCHBbkqmqOjS0ZiPwJuDFVfVgkmcs1cCSpMXp8wj/EmCmqg5X1SPAHmD7vDWvBW6qqgcBqurYeMeUJI2qT/DXAfcPHR/prht2EXBRki8kOZBk84m+UZKdSaaTTM/Ozi5uYknSoozrSdvVwEbgMmAH8MEk585fVFW7qmqyqiYnJibGdNeSpD76BP8osGHoeH133bAjwFRVPVpVXwe+yuAHgCTpFNEn+LcBG5NcmGQNcCUwNW/NJxk8uifJWganeA6PcU5J0ogWDH5VHQeuAfYDdwF7q+pgkhuSbOuW7Qe+leQQcAvwxqr61lINLUl64lJVK3LHk5OTNT09vSL3LUmnqyS3V9XkYr7Wd9pKUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiN6BT/J5iR3J5lJct3jrHtFkkoyOb4RJUnjsGDwk6wCbgK2AJuAHUk2nWDdOcAfA18a95CSpNH1eYR/CTBTVYer6hFgD7D9BOveDrwT+P4Y55MkjUmf4K8D7h86PtJd93+SXAxsqKpPPd43SrIzyXSS6dnZ2Sc8rCRp8UZ+0jbJWcC7gGsXWltVu6pqsqomJyYmRr1rSdIT0Cf4R4ENQ8fru+secw7wQuBzSe4BLgWmfOJWkk4tfYJ/G7AxyYVJ1gBXAlOP3VhVD1XV2qq6oKouAA4A26pqekkmliQtyoLBr6rjwDXAfuAuYG9VHUxyQ5JtSz2gJGk8VvdZVFX7gH3zrrv+JGsvG30sSdK4+U5bSWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRvQKfpLNSe5OMpPkuhPc/oYkh5LcmeSzSc4f/6iSpFEsGPwkq4CbgC3AJmBHkk3zlt0BTFbVzwCfAP5q3INKkkbT5xH+JcBMVR2uqkeAPcD24QVVdUtVPdwdHgDWj3dMSdKo+gR/HXD/0PGR7rqTuRr49IluSLIzyXSS6dnZ2f5TSpJGNtYnbZNcBUwCN57o9qraVVWTVTU5MTExzruWJC1gdY81R4ENQ8fru+v+nyRXAG8GXlJVPxjPeJKkcenzCP82YGOSC5OsAa4EpoYXJHkR8AFgW1UdG/+YkqRRLRj8qjoOXAPsB+4C9lbVwSQ3JNnWLbsReCrw8ST/mWTqJN9OkrRC+pzSoar2AfvmXXf90OUrxjyXJGnMfKetJDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDWiV/CTbE5yd5KZJNed4Pazk3ysu/1LSS4Y96CSpNEsGPwkq4CbgC3AJmBHkk3zll0NPFhVzwXeDbxz3INKkkbT5xH+JcBMVR2uqkeAPcD2eWu2A//YXf4EcHmSjG9MSdKoVvdYsw64f+j4CPCLJ1tTVceTPAT8FPDN4UVJdgI7u8MfJPnKYoY+A61l3l41zL2Y417McS/mPG+xX9gn+GNTVbuAXQBJpqtqcjnv/1TlXsxxL+a4F3PcizlJphf7tX1O6RwFNgwdr++uO+GaJKuBpwPfWuxQkqTx6xP824CNSS5Msga4Epiat2YK+L3u8m8B/1ZVNb4xJUmjWvCUTndO/hpgP7AK+FBVHUxyAzBdVVPA3wMfTTIDfJvBD4WF7Bph7jONezHHvZjjXsxxL+Ysei/iA3FJaoPvtJWkRhh8SWrEkgffj2WY02Mv3pDkUJI7k3w2yfkrMedyWGgvhta9IkklOWNfktdnL5K8svu7cTDJ7uWecbn0+DdyXpJbktzR/TvZuhJzLrUkH0py7GTvVcrAe7t9ujPJxb2+cVUt2R8GT/J+DXgOsAb4MrBp3po/AN7fXb4S+NhSzrRSf3ruxa8BP9Fdfl3Le9GtOwe4FTgATK703Cv492IjcAfwk93xM1Z67hXci13A67rLm4B7VnruJdqLXwUuBr5yktu3Ap8GAlwKfKnP913qR/h+LMOcBfeiqm6pqoe7wwMM3vNwJurz9wLg7Qw+l+n7yzncMuuzF68FbqqqBwGq6tgyz7hc+uxFAU/rLj8deGAZ51s2VXUrg1c8nsx24CM1cAA4N8mzFvq+Sx38E30sw7qTramq48BjH8twpumzF8OuZvAT/Ey04F50v6JuqKpPLedgK6DP34uLgIuSfCHJgSSbl2265dVnL94GXJXkCLAPeP3yjHbKeaI9AZb5oxXUT5KrgEngJSs9y0pIchbwLuDVKzzKqWI1g9M6lzH4re/WJD9dVd9Z0alWxg7gw1X1N0l+icH7f15YVT9a6cFOB0v9CN+PZZjTZy9IcgXwZmBbVf1gmWZbbgvtxTnAC4HPJbmHwTnKqTP0ids+fy+OAFNV9WhVfR34KoMfAGeaPntxNbAXoKq+CDyZwQertaZXT+Zb6uD7sQxzFtyLJC8CPsAg9mfqeVpYYC+q6qGqWltVF1TVBQyez9hWVYv+0KhTWJ9/I59k8OieJGsZnOI5vJxDLpM+e3EfcDlAkhcwCP7ssk55apgCXtW9WudS4KGq+sZCX7Skp3Rq6T6W4bTTcy9uBJ4KfLx73vq+qtq2YkMvkZ570YSee7EfeFmSQ8APgTdW1Rn3W3DPvbgW+GCSP2XwBO6rz8QHiEluZvBDfm33fMVbgScBVNX7GTx/sRWYAR4GXtPr+56BeyVJOgHfaStJjTD4ktQIgy9JjTD4ktQIgy9JjTD4ktQIgy9JjfhfCpQeyxWfejwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
