{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad accumulation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAD_POOL = 2\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = \"../models/large-uncased-3\"\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 3\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190514-220631.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 439 ms, total: 5.05 s\n",
      "Wall time: 8.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:13<00:00, 136839.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 1.17 s, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:27<00:00, 66372.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 s, sys: 866 ms, total: 27.1 s\n",
      "Wall time: 28.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "        f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, i_fold, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, i_fold, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  158.3\n",
      "epoch start: from start  0.2, from old  158.3\n",
      "start fold 0\n",
      "toxic ratio dev: 0.17379875481128693, val: 0.1735895723104477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpo33gq1gq\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402757120\n",
      "loaders 1568956416\n",
      "i_epoch 0 start: from start  83.7, from old  158.4\n",
      "epoch_start: 0 1568956416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 19:29:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  16978.5, from old  241.9\n",
      "after model save: from start  16981.7, from old  17136.7\n",
      "after gc.collect: from start  16983.9, from old  17139.9\n",
      "after gc.collect: from start  16998.3, from old  17142.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  33926.0, from old  17156.6\n",
      "after model save: from start  33929.0, from old  34084.3\n",
      "after gc.collect: from start  33931.2, from old  34087.2\n",
      "after gc.collect: from start  33937.4, from old  34089.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:25<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  50859.5, from old  34095.7\n",
      "after model save: from start  50862.6, from old  51017.7\n",
      "after gc.collect: from start  50864.7, from old  51020.8\n",
      "after gc.collect: from start  50871.0, from old  51023.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:23<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  67781.3, from old  51029.2\n",
      "after model save: from start  67783.9, from old  67939.6\n",
      "after gc.collect: from start  67786.1, from old  67942.2\n",
      "after gc.collect: from start  67792.4, from old  67944.4\n",
      "after dev all batch: from start  67793.4, from old  67950.6\n",
      "after dev loop 5607045632\n",
      "after all batch gc.collect(): from start  67795.5, from old  67951.7\n",
      "i_epoch 1 start: from start  67795.5, from old  67953.8\n",
      "epoch_start: 1 5607045632\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 19:27:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:26<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  84685.3, from old  67953.8\n",
      "after model save: from start  84688.5, from old  84843.5\n",
      "after gc.collect: from start  84690.8, from old  84846.7\n",
      "after gc.collect: from start  84697.1, from old  84849.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  101605.5, from old  84855.4\n",
      "after model save: from start  101607.7, from old  101763.7\n",
      "after gc.collect: from start  101609.9, from old  101766.0\n",
      "after gc.collect: from start  101615.8, from old  101768.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  118526.7, from old  101774.1\n",
      "after model save: from start  118529.2, from old  118685.0\n",
      "after gc.collect: from start  118531.3, from old  118687.4\n",
      "after gc.collect: from start  118537.2, from old  118689.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:24<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  135442.6, from old  118695.4\n",
      "after model save: from start  135445.3, from old  135600.9\n",
      "after gc.collect: from start  135447.4, from old  135603.5\n",
      "after gc.collect: from start  135453.2, from old  135605.6\n",
      "after dev all batch: from start  135454.3, from old  135611.5\n",
      "after dev loop 5607045120\n",
      "after all batch gc.collect(): from start  135456.4, from old  135612.6\n",
      "i_epoch 2 start: from start  135456.4, from old  135614.6\n",
      "epoch_start: 2 5607045120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 19:28:57<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  152361.2, from old  135614.6\n",
      "after model save: from start  152363.9, from old  152519.4\n",
      "after gc.collect: from start  152365.9, from old  152522.1\n",
      "after gc.collect: from start  152371.8, from old  152524.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:27<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  169300.1, from old  152530.0\n",
      "after model save: from start  169302.6, from old  169458.3\n",
      "after gc.collect: from start  169304.7, from old  169460.8\n",
      "after gc.collect: from start  169310.6, from old  169462.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:26<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  186229.0, from old  169468.8\n",
      "after model save: from start  186231.6, from old  186387.3\n",
      "after gc.collect: from start  186233.8, from old  186389.9\n",
      "after gc.collect: from start  186239.6, from old  186392.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:25<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  203162.9, from old  186397.9\n",
      "after model save: from start  203165.4, from old  203321.2\n",
      "after gc.collect: from start  203167.6, from old  203323.7\n",
      "after gc.collect: from start  203173.4, from old  203325.8\n",
      "after dev all batch: from start  203174.5, from old  203331.7\n",
      "after dev loop 5607046144\n",
      "after all batch gc.collect(): from start  203176.6, from old  203332.8\n",
      "after all folds: from start  203176.6, from old  203334.9\n",
      "after all folds, gc collect: from start  203178.9, from old  203334.9\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7561e+04, 3.1961e+04, 1.6081e+04, 8.1280e+03, 5.6660e+03,\n",
       "        3.3400e+03, 2.5220e+03, 1.7370e+03, 1.0410e+03, 9.7000e+02,\n",
       "        4.3400e+02, 7.8100e+02, 3.3300e+02, 0.0000e+00, 2.9600e+02,\n",
       "        2.5600e+02, 0.0000e+00, 2.1700e+02, 1.7800e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.4200e+02, 0.0000e+00, 0.0000e+00, 1.0500e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([  1. ,   6.1,  11.2,  16.3,  21.4,  26.5,  31.6,  36.7,  41.8,\n",
       "         46.9,  52. ,  57.1,  62.2,  67.3,  72.4,  77.5,  82.6,  87.7,\n",
       "         92.8,  97.9, 103. , 108.1, 113.2, 118.3, 123.4, 128.5, 133.6,\n",
       "        138.7, 143.8, 148.9, 154. , 159.1, 164.2, 169.3, 174.4, 179.5,\n",
       "        184.6, 189.7, 194.8, 199.9, 205. , 210.1, 215.2, 220.3, 225.4,\n",
       "        230.5, 235.6, 240.7, 245.8, 250.9, 256. ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (12,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (12,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
