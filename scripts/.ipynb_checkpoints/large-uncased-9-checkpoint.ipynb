{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad accum 8\n",
    "\n",
    "n_oov だけ落とす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAD_POOL = 8\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-uncased-8-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "DROP_SENTENCE_FEATURES = ['n_oov', 'n_oov_ratio']\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 2\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190527-130352.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.drop(columns=DROP_SENTENCE_FEATURES).values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 s, sys: 341 ms, total: 5.47 s\n",
      "Wall time: 8.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:14<00:00, 120338.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.34 s, total: 15.1 s\n",
      "Wall time: 15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:34<00:00, 51875.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 s, sys: 1.06 s, total: 34.6 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "    \n",
    "    if i_validation == 7:\n",
    "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "            f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, i_fold, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, i_fold, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  181.0\n",
      "epoch start: from start  0.2, from old  181.0\n",
      "start fold 0\n",
      "toxic ratio dev: 0.17379875481128693, val: 0.1735895723104477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpe6wnm7t4\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402757120\n",
      "loaders 1554538496\n",
      "i_epoch 0 start: from start  123.2, from old  181.2\n",
      "epoch_start: 0 1554538496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:32:56<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:49<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  16208.3, from old  304.3\n",
      "after model save: from start  16208.3, from old  16389.3\n",
      "after gc.collect: from start  16210.6, from old  16389.3\n",
      "after gc.collect: from start  16222.7, from old  16391.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:56<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  32270.9, from old  16403.7\n",
      "after model save: from start  32270.9, from old  32452.0\n",
      "after gc.collect: from start  32273.1, from old  32452.0\n",
      "after gc.collect: from start  32279.7, from old  32454.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  48340.5, from old  32460.7\n",
      "after model save: from start  48340.5, from old  48521.5\n",
      "after gc.collect: from start  48342.6, from old  48521.5\n",
      "after gc.collect: from start  48348.8, from old  48523.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  64416.6, from old  48529.9\n",
      "after model save: from start  64416.6, from old  64597.7\n",
      "after gc.collect: from start  64418.7, from old  64597.7\n",
      "after gc.collect: from start  64425.0, from old  64599.7\n",
      "after dev all batch: from start  64426.1, from old  64606.0\n",
      "after dev loop 5677037568\n",
      "after all batch gc.collect(): from start  64428.2, from old  64607.1\n",
      "i_epoch 1 start: from start  64428.2, from old  64609.2\n",
      "epoch_start: 1 5677037568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:30:45<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:53<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  80485.7, from old  64609.2\n",
      "after model save: from start  80485.7, from old  80666.8\n",
      "after gc.collect: from start  80487.8, from old  80666.8\n",
      "after gc.collect: from start  80494.3, from old  80668.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:51<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  96545.6, from old  80675.4\n",
      "after model save: from start  96545.6, from old  96726.6\n",
      "after gc.collect: from start  96547.7, from old  96726.6\n",
      "after gc.collect: from start  96554.2, from old  96728.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  112595.9, from old  96735.2\n",
      "after model save: from start  112595.9, from old  112777.0\n",
      "after gc.collect: from start  112598.0, from old  112777.0\n",
      "after gc.collect: from start  112604.6, from old  112779.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  128654.9, from old  112785.6\n",
      "after model save: from start  128656.2, from old  128835.9\n",
      "after gc.collect: from start  128658.4, from old  128837.2\n",
      "after gc.collect: from start  128665.2, from old  128839.4\n",
      "after dev all batch: from start  128666.4, from old  128846.3\n",
      "after dev loop 5677038080\n",
      "after all batch gc.collect(): from start  128668.5, from old  128847.4\n",
      "after all folds: from start  128668.5, from old  128849.6\n",
      "after all folds, gc collect: from start  128670.7, from old  128849.6\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7561e+04, 3.1961e+04, 1.6081e+04, 8.1280e+03, 5.6660e+03,\n",
       "        3.3400e+03, 2.5220e+03, 1.7370e+03, 1.0410e+03, 9.7000e+02,\n",
       "        4.3400e+02, 7.8100e+02, 3.3300e+02, 0.0000e+00, 2.9600e+02,\n",
       "        2.5600e+02, 0.0000e+00, 2.1700e+02, 1.7800e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.4200e+02, 0.0000e+00, 0.0000e+00, 1.0500e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([  1. ,   6.1,  11.2,  16.3,  21.4,  26.5,  31.6,  36.7,  41.8,\n",
       "         46.9,  52. ,  57.1,  62.2,  67.3,  72.4,  77.5,  82.6,  87.7,\n",
       "         92.8,  97.9, 103. , 108.1, 113.2, 118.3, 123.4, 128.5, 133.6,\n",
       "        138.7, 143.8, 148.9, 154. , 159.1, 164.2, 169.3, 174.4, 179.5,\n",
       "        184.6, 189.7, 194.8, 199.9, 205. , 210.1, 215.2, 220.3, 225.4,\n",
       "        230.5, 235.6, 240.7, 245.8, 250.9, 256. ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
