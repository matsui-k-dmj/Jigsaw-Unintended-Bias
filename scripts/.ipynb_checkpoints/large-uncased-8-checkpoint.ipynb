{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad accum 8\n",
    "\n",
    "good sentence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAD_POOL = 8\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-uncased-7-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "SENTENCE_FEAURE_USED = ['word_count', 'n_unique', 'n_unique_ratio']\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 2\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190526-010341.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df[SENTENCE_FEAURE_USED].values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.94 s, sys: 373 ms, total: 5.31 s\n",
      "Wall time: 8.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:13<00:00, 135371.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 1.5 s, total: 13.4 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:26<00:00, 67423.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 866 ms, total: 26.6 s\n",
      "Wall time: 27.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "    \n",
    "    if i_validation == 7:\n",
    "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "            f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, i_fold, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, i_fold, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  161.1\n",
      "epoch start: from start  0.1, from old  161.1\n",
      "start fold 0\n",
      "toxic ratio dev: 0.17379875481128693, val: 0.1735895723104477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmp0nd8i72k\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402756608\n",
      "loaders 1482317312\n",
      "i_epoch 0 start: from start  83.0, from old  161.2\n",
      "epoch_start: 0 1482317312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 17:00:16<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:07<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  14771.7, from old  244.1\n",
      "after model save: from start  14771.7, from old  14932.8\n",
      "after gc.collect: from start  14774.0, from old  14932.8\n",
      "after gc.collect: from start  14788.1, from old  14935.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:08<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  29508.1, from old  14949.2\n",
      "after model save: from start  29508.1, from old  29669.1\n",
      "after gc.collect: from start  29510.2, from old  29669.1\n",
      "after gc.collect: from start  29516.8, from old  29671.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  44228.7, from old  29677.8\n",
      "after model save: from start  44228.7, from old  44389.7\n",
      "after gc.collect: from start  44230.7, from old  44389.7\n",
      "after gc.collect: from start  44237.2, from old  44391.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:07<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  58959.0, from old  44398.3\n",
      "after model save: from start  58959.0, from old  59120.0\n",
      "after gc.collect: from start  58961.0, from old  59120.0\n",
      "after gc.collect: from start  58967.4, from old  59122.1\n",
      "after dev all batch: from start  58968.5, from old  59128.5\n",
      "after dev loop 5518570496\n",
      "after all batch gc.collect(): from start  58970.5, from old  59129.5\n",
      "i_epoch 1 start: from start  58970.5, from old  59131.6\n",
      "epoch_start: 1 5518570496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 17:00:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:09<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  73690.2, from old  59131.6\n",
      "after model save: from start  73690.2, from old  73851.3\n",
      "after gc.collect: from start  73692.3, from old  73851.3\n",
      "after gc.collect: from start  73698.7, from old  73853.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  88424.7, from old  73859.8\n",
      "after model save: from start  88424.7, from old  88585.8\n",
      "after gc.collect: from start  88426.8, from old  88585.8\n",
      "after gc.collect: from start  88433.2, from old  88587.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:10<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  103147.6, from old  88594.3\n",
      "after model save: from start  103147.6, from old  103308.7\n",
      "after gc.collect: from start  103149.7, from old  103308.7\n",
      "after gc.collect: from start  103156.1, from old  103310.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 45:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  117938.6, from old  103317.1\n",
      "after model save: from start  117941.1, from old  118099.7\n",
      "after gc.collect: from start  117943.3, from old  118102.2\n",
      "after gc.collect: from start  117950.0, from old  118104.4\n",
      "after dev all batch: from start  117951.0, from old  118111.1\n",
      "after dev loop 5518569472\n",
      "after all batch gc.collect(): from start  117953.1, from old  118112.1\n",
      "after all folds: from start  117953.1, from old  118114.2\n",
      "after all folds, gc collect: from start  117955.4, from old  118114.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7561e+04, 3.1961e+04, 1.6081e+04, 8.1280e+03, 5.6660e+03,\n",
       "        3.3400e+03, 2.5220e+03, 1.7370e+03, 1.0410e+03, 9.7000e+02,\n",
       "        4.3400e+02, 7.8100e+02, 3.3300e+02, 0.0000e+00, 2.9600e+02,\n",
       "        2.5600e+02, 0.0000e+00, 2.1700e+02, 1.7800e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.4200e+02, 0.0000e+00, 0.0000e+00, 1.0500e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([  1. ,   6.1,  11.2,  16.3,  21.4,  26.5,  31.6,  36.7,  41.8,\n",
       "         46.9,  52. ,  57.1,  62.2,  67.3,  72.4,  77.5,  82.6,  87.7,\n",
       "         92.8,  97.9, 103. , 108.1, 113.2, 118.3, 123.4, 128.5, 133.6,\n",
       "        138.7, 143.8, 148.9, 154. , 159.1, 164.2, 169.3, 174.4, 179.5,\n",
       "        184.6, 189.7, 194.8, 199.9, 205. , 210.1, 215.2, 220.3, 225.4,\n",
       "        230.5, 235.6, 240.7, 245.8, 250.9, 256. ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAExtJREFUeJzt3H+MndV95/H3p3bIojYJJkwtZDtr0lqpaKQkzghcNaq6QTUGVjUrpRHRqrYib7xSYJVKXe062z/oJo1EVtpmg5SissUbE2VDUdoIqzF1vQ5RtX9APDQEMJR6SkDYMtiNCXQ3arKk3/3jHre3PjOeO+MfdzzzfklX9zzf5zzPPUePNR8/P+5NVSFJ0rCfGPcAJEmLj+EgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkzkjhkOSKJF9N8pdJnk3yC0muTHIgyZH2vqr1TZK7k0wneTLJxqH9bG/9jyTZPlR/f5Kn2jZ3J8n5n6okaVSjnjl8HvjTqvo54D3As8Au4GBVbQAOtmWAm4AN7bUTuAcgyZXAncD1wHXAnacDpfX52NB2W85tWpKkc5G5viGd5G3AE8A7a6hzkueAX66q40muBr5ZVe9K8vut/ZXhfqdfVfVvW/33gW+21yMteEjykeF+s7nqqqtq/fr1852vJC1bjz/++N9U1cQofVeO0Oca4CTwP5K8B3gc+ASwuqqOtz4vA6tbew3w0tD2R1vtbPWjM9TPav369UxNTY0wfEkSQJIXR+07ymWllcBG4J6qeh/wf/nHS0gAtDOKC/4jTUl2JplKMnXy5MkL/XGStGyNEg5HgaNV9Vhb/iqDsHilXU6ivZ9o648B64a2X9tqZ6uvnaHeqap7q2qyqiYnJkY6M5IkLcCc4VBVLwMvJXlXK90APAPsBU4/cbQdeKi19wLb2lNLm4DX2uWn/cDmJKvajejNwP627vUkm9pTStuG9iVJGoNR7jkA/Dvgy0kuA54HPsogWB5MsgN4Efhw67sPuBmYBn7Q+lJVp5J8GjjU+n2qqk619seBLwKXAw+3lyRpTOZ8WmmxmpycLG9IS9LokjxeVZOj9PUb0pKkjuEgSeoYDpKkjuEgSeqM+rTSkrJ+19dnrL9w1y0XeSSStDh55iBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqTOSOGQ5IUkTyV5IslUq12Z5ECSI+19Vasnyd1JppM8mWTj0H62t/5Hkmwfqr+/7X+6bZvzPVFJ0ujmc+bwL6rqvVU12ZZ3AQeragNwsC0D3ARsaK+dwD0wCBPgTuB64DrgztOB0vp8bGi7LQuekSTpnJ3LZaWtwJ7W3gPcOlS/vwYeBa5IcjVwI3Cgqk5V1avAAWBLW/fWqnq0qgq4f2hfkqQxGDUcCvizJI8n2dlqq6vqeGu/DKxu7TXAS0PbHm21s9WPzlCXJI3JyhH7faCqjiX5aeBAkr8cXllVlaTO//D+qRZMOwHe8Y53XOiPk6Rla6Qzh6o61t5PAF9jcM/glXZJiPZ+onU/Bqwb2nxtq52tvnaG+kzjuLeqJqtqcmJiYpShS5IWYM5wSPKTSd5yug1sBp4G9gKnnzjaDjzU2nuBbe2ppU3Aa+3y035gc5JV7Ub0ZmB/W/d6kk3tKaVtQ/uSJI3BKJeVVgNfa0+XrgT+Z1X9aZJDwINJdgAvAh9u/fcBNwPTwA+AjwJU1akknwYOtX6fqqpTrf1x4IvA5cDD7SVJGpM5w6GqngfeM0P9e8ANM9QLuH2Wfe0Gds9QnwLePcJ4JUkXgd+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1Rg6HJCuSfDvJn7Tla5I8lmQ6yR8muazV39yWp9v69UP7+GSrP5fkxqH6llabTrLr/E1PkrQQ8zlz+ATw7NDyZ4HPVdXPAq8CO1p9B/Bqq3+u9SPJtcBtwM8DW4Dfa4GzAvgCcBNwLfCR1leSNCYjhUOStcAtwB+05QAfBL7auuwBbm3trW2Ztv6G1n8r8EBV/bCqvgtMA9e113RVPV9VPwIeaH0lSWMy6pnDfwP+A/D3bfntwPer6o22fBRY09prgJcA2vrXWv9/qJ+xzWx1SdKYzBkOSf4lcKKqHr8I45lrLDuTTCWZOnny5LiHI0lL1ihnDr8I/GqSFxhc8vkg8HngiiQrW5+1wLHWPgasA2jr3wZ8b7h+xjaz1TtVdW9VTVbV5MTExAhDlyQtxJzhUFWfrKq1VbWewQ3lb1TVvwYeAT7Uum0HHmrtvW2Ztv4bVVWtflt7mukaYAPwLeAQsKE9/XRZ+4y952V2kqQFWTl3l1n9R+CBJL8DfBu4r9XvA76UZBo4xeCPPVV1OMmDwDPAG8DtVfVjgCR3APuBFcDuqjp8DuOSJJ2jeYVDVX0T+GZrP8/gSaMz+/wd8GuzbP8Z4DMz1PcB++YzFknSheM3pCVJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktRZOe4BLCbrd319xvoLd91ykUciSePlmYMkqWM4SJI6c4ZDkn+W5FtJvpPkcJL/3OrXJHksyXSSP0xyWau/uS1Pt/Xrh/b1yVZ/LsmNQ/UtrTadZNf5n6YkaT5GOXP4IfDBqnoP8F5gS5JNwGeBz1XVzwKvAjta/x3Aq63+udaPJNcCtwE/D2wBfi/JiiQrgC8ANwHXAh9pfSVJYzJnONTA/2mLb2qvAj4IfLXV9wC3tvbWtkxbf0OStPoDVfXDqvouMA1c117TVfV8Vf0IeKD1lSSNyUj3HNr/8J8ATgAHgL8Gvl9Vb7QuR4E1rb0GeAmgrX8NePtw/YxtZqtLksZkpHCoqh9X1XuBtQz+p/9zF3RUs0iyM8lUkqmTJ0+OYwiStCzM62mlqvo+8AjwC8AVSU5/T2ItcKy1jwHrANr6twHfG66fsc1s9Zk+/96qmqyqyYmJifkMXZI0D6M8rTSR5IrWvhz4FeBZBiHxodZtO/BQa+9ty7T136iqavXb2tNM1wAbgG8Bh4AN7emnyxjctN57PiYnSVqYUb4hfTWwpz1V9BPAg1X1J0meAR5I8jvAt4H7Wv/7gC8lmQZOMfhjT1UdTvIg8AzwBnB7Vf0YIMkdwH5gBbC7qg6ftxlKkuZtznCoqieB981Qf57B/Ycz638H/Nos+/oM8JkZ6vuAfSOMV5J0EfgNaUlSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSZ85wSLIuySNJnklyOMknWv3KJAeSHGnvq1o9Se5OMp3kySQbh/a1vfU/kmT7UP39SZ5q29ydJBdispKk0Yxy5vAG8JtVdS2wCbg9ybXALuBgVW0ADrZlgJuADe21E7gHBmEC3AlcD1wH3Hk6UFqfjw1tt+XcpyZJWqg5w6GqjlfVX7T23wLPAmuArcCe1m0PcGtrbwXur4FHgSuSXA3cCByoqlNV9SpwANjS1r21qh6tqgLuH9qXJGkM5nXPIcl64H3AY8DqqjreVr0MrG7tNcBLQ5sdbbWz1Y/OUJckjcnI4ZDkp4A/An6jql4fXtf+x1/neWwzjWFnkqkkUydPnrzQHydJy9ZI4ZDkTQyC4ctV9cet/Eq7JER7P9Hqx4B1Q5uvbbWz1dfOUO9U1b1VNVlVkxMTE6MMXZK0AKM8rRTgPuDZqvrdoVV7gdNPHG0HHhqqb2tPLW0CXmuXn/YDm5OsajeiNwP727rXk2xqn7VtaF+SpDFYOUKfXwR+HXgqyROt9p+Au4AHk+wAXgQ+3NbtA24GpoEfAB8FqKpTST4NHGr9PlVVp1r748AXgcuBh9tLkjQmc4ZDVf1vYLbvHdwwQ/8Cbp9lX7uB3TPUp4B3zzUWSdLF4TekJUkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEmdUX4+Y9lbv+vrM9ZfuOuWizwSSbo4PHOQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHUMB0lSx3CQJHXmDIcku5OcSPL0UO3KJAeSHGnvq1o9Se5OMp3kySQbh7bZ3vofSbJ9qP7+JE+1be5OkvM9SUnS/Ixy5vBFYMsZtV3AwaraABxsywA3ARvaaydwDwzCBLgTuB64DrjzdKC0Ph8b2u7Mz5IkXWRzhkNV/Tlw6ozyVmBPa+8Bbh2q318DjwJXJLkauBE4UFWnqupV4ACwpa17a1U9WlUF3D+0L0nSmCz0nsPqqjre2i8Dq1t7DfDSUL+jrXa2+tEZ6pKkMTrnG9Ltf/x1HsYypyQ7k0wlmTp58uTF+EhJWpYWGg6vtEtCtPcTrX4MWDfUb22rna2+dob6jKrq3qqarKrJiYmJBQ5dkjSXhYbDXuD0E0fbgYeG6tvaU0ubgNfa5af9wOYkq9qN6M3A/rbu9SSb2lNK24b2JUkak5VzdUjyFeCXgauSHGXw1NFdwINJdgAvAh9u3fcBNwPTwA+AjwJU1akknwYOtX6fqqrTN7k/zuCJqMuBh9tLkjRGc4ZDVX1kllU3zNC3gNtn2c9uYPcM9Sng3XONQ5J08fgNaUlSx3CQJHXmvKyk2a3f9fUZ6y/cdctFHokknV+eOUiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOn7P4QLw+w+SLnWeOUiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKnjl+AuIr8cJ+lS4ZmDJKljOEiSOl5WWgS83CRpsfHMQZLUMRwkSR0vKy1iXm6SNC6eOUiSOovmzCHJFuDzwArgD6rqrjEPadGa7YzibDzbkDQfiyIckqwAvgD8CnAUOJRkb1U9M96RLX1eupI0k0URDsB1wHRVPQ+Q5AFgK2A4nCcLOduQtHwtlnBYA7w0tHwUuH5MYxHzP6OYb/hc6P2czfk6W/KsS0tZqmrcYyDJh4AtVfVv2vKvA9dX1R1n9NsJ7GyL7wKeW8DHXQX8zTkM91KynOYKzncpW05zhQs3339eVROjdFwsZw7HgHVDy2tb7Z+oqnuBe8/lg5JMVdXkuezjUrGc5grOdylbTnOFxTHfxfIo6yFgQ5JrklwG3AbsHfOYJGnZWhRnDlX1RpI7gP0MHmXdXVWHxzwsSVq2FkU4AFTVPmDfRfioc7osdYlZTnMF57uULae5wiKY76K4IS1JWlwWyz0HSdIismzCIcmWJM8lmU6ya9zjuRCSvJDkqSRPJJlqtSuTHEhypL2vGvc4FyrJ7iQnkjw9VJtxfhm4ux3vJ5NsHN/I52+Wuf52kmPt+D6R5OahdZ9sc30uyY3jGfXCJVmX5JEkzyQ5nOQTrb7kju9Z5rq4jm9VLfkXg5vcfw28E7gM+A5w7bjHdQHm+QJw1Rm1/wLsau1dwGfHPc5zmN8vARuBp+eaH3Az8DAQYBPw2LjHfx7m+tvAv5+h77Xt3/SbgWvav/UV457DPOd7NbCxtd8C/FWb15I7vmeZ66I6vsvlzOEffp6jqn4EnP55juVgK7CntfcAt45xLOekqv4cOHVGebb5bQXur4FHgSuSXH1xRnruZpnrbLYCD1TVD6vqu8A0g3/zl4yqOl5Vf9Hafws8y+CXE5bc8T3LXGczluO7XMJhpp/nONvBuFQV8GdJHm/fJgdYXVXHW/tlYPV4hnbBzDa/pXrM72iXUXYPXSJcUnNNsh54H/AYS/z4njFXWETHd7mEw3LxgaraCNwE3J7kl4ZX1uAcdck+nrbU5wfcA/wM8F7gOPBfxzuc8y/JTwF/BPxGVb0+vG6pHd8Z5rqoju9yCYeRfp7jUldVx9r7CeBrDE49Xzl9ut3eT4xvhBfEbPNbcse8ql6pqh9X1d8D/51/vLSwJOaa5E0M/lh+uar+uJWX5PGdaa6L7fgul3BY8j/PkeQnk7zldBvYDDzNYJ7bW7ftwEPjGeEFM9v89gLb2lMtm4DXhi5PXJLOuKb+rxgcXxjM9bYkb05yDbAB+NbFHt+5SBLgPuDZqvrdoVVL7vjONtdFd3zHfef+Yr0YPN3wVwzu9P/WuMdzAeb3TgZPNHwHOHx6jsDbgYPAEeB/AVeOe6znMMevMDjd/n8MrrvumG1+DJ5i+UI73k8Bk+Me/3mY65faXJ5k8Afj6qH+v9Xm+hxw07jHv4D5foDBJaMngSfa6+aleHzPMtdFdXz9hrQkqbNcLitJkubBcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdf4/KUifhh/sHMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
