{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold 2\n",
    "\n",
    "grad accumulation!\n",
    "\n",
    "n_oov も絶対いらんし抜こ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAD_POOL = 8\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-uncased-11-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 2\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "I_FOLD = 2\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190609-073651.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.drop(columns=['n_oov']).values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 s, sys: 377 ms, total: 5.19 s\n",
      "Wall time: 8.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:15<00:00, 117489.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 1.62 s, total: 15.4 s\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:32<00:00, 55962.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 s, sys: 869 ms, total: 32.3 s\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "\n",
    "    if i_validation == 7:\n",
    "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "            f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, 0, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, 0, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  164.7\n",
      "epoch start: from start  0.1, from old  164.7\n",
      "start fold 2\n",
      "toxic ratio dev: 0.1737252026796341, val: 0.1742515116930008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpixu56f2j\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402757120\n",
      "loaders 1561747456\n",
      "i_epoch 0 start: from start  105.5, from old  164.8\n",
      "epoch_start: 0 1561747456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131958' class='' max='131958', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131958/131958 18:26:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:20<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  16031.2, from old  270.2\n",
      "after model save: from start  16031.2, from old  16195.9\n",
      "after gc.collect: from start  16033.6, from old  16195.9\n",
      "after gc.collect: from start  16048.0, from old  16198.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  32016.2, from old  16212.7\n",
      "after model save: from start  32016.2, from old  32180.8\n",
      "after gc.collect: from start  32018.3, from old  32180.8\n",
      "after gc.collect: from start  32024.9, from old  32183.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:20<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  48014.3, from old  32189.6\n",
      "after model save: from start  48014.3, from old  48179.0\n",
      "after gc.collect: from start  48016.4, from old  48179.0\n",
      "after gc.collect: from start  48022.7, from old  48181.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:20<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  64010.6, from old  48187.4\n",
      "after model save: from start  64010.6, from old  64175.3\n",
      "after gc.collect: from start  64012.6, from old  64175.3\n",
      "after gc.collect: from start  64019.0, from old  64177.3\n",
      "after dev all batch: from start  64020.0, from old  64183.7\n",
      "after dev loop 5598524928\n",
      "after all batch gc.collect(): from start  64022.1, from old  64184.7\n",
      "i_epoch 1 start: from start  64022.1, from old  64186.8\n",
      "epoch_start: 1 5598524928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131958' class='' max='131958', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131958/131958 18:27:16<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:18<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  80016.5, from old  64186.8\n",
      "after model save: from start  80016.5, from old  80181.2\n",
      "after gc.collect: from start  80018.6, from old  80181.2\n",
      "after gc.collect: from start  80025.1, from old  80183.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:16<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  96031.2, from old  80189.8\n",
      "after model save: from start  96031.2, from old  96195.9\n",
      "after gc.collect: from start  96033.3, from old  96195.9\n",
      "after gc.collect: from start  96039.8, from old  96198.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:17<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  112027.3, from old  96204.5\n",
      "after model save: from start  112027.3, from old  112192.0\n",
      "after gc.collect: from start  112029.3, from old  112192.0\n",
      "after gc.collect: from start  112035.8, from old  112194.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14649' class='' max='14649', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14649/14649 50:17<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  128030.0, from old  112200.5\n",
      "after model save: from start  128031.2, from old  128194.7\n",
      "after gc.collect: from start  128033.3, from old  128195.9\n",
      "after gc.collect: from start  128040.5, from old  128198.0\n",
      "after dev all batch: from start  128041.5, from old  128205.2\n",
      "after dev loop 5598524928\n",
      "after all batch gc.collect(): from start  128043.7, from old  128206.2\n",
      "after all folds: from start  128043.7, from old  128208.3\n",
      "after all folds, gc collect: from start  128045.9, from old  128208.3\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold != I_FOLD:\n",
    "            continue\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, 0, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
