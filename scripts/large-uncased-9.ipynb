{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length quantile = 1\n",
    "\n",
    "grad accum 8\n",
    "\n",
    "n_oov だけ落とす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_QUANTILE = 1\n",
    "\n",
    "N_GRAD_POOL = 8\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-uncased-8-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "DROP_SENTENCE_FEATURES = ['n_oov', 'n_oov_ratio']\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 2\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190529-135628.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.drop(columns=DROP_SENTENCE_FEATURES).values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.75 s, sys: 379 ms, total: 5.13 s\n",
      "Wall time: 8.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:15<00:00, 119911.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 1.4 s, total: 15.1 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at ../bert-cache/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:31<00:00, 57295.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 790 ms, total: 31.5 s\n",
      "Wall time: 32.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "    \n",
    "    if i_validation == 7:\n",
    "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "            f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, i_fold, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, i_fold, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  174.2\n",
      "epoch start: from start  0.2, from old  174.3\n",
      "start fold 0\n",
      "toxic ratio dev: 0.17379875481128693, val: 0.1735895723104477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmp04hx05q7\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1402757120\n",
      "loaders 1554538496\n",
      "i_epoch 0 start: from start  109.0, from old  174.5\n",
      "epoch_start: 0 1554538496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:32:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  16129.4, from old  283.3\n",
      "after model save: from start  16129.4, from old  16303.6\n",
      "after gc.collect: from start  16131.6, from old  16303.6\n",
      "after gc.collect: from start  16146.3, from old  16305.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:54<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  32209.3, from old  16320.6\n",
      "after model save: from start  32209.3, from old  32383.6\n",
      "after gc.collect: from start  32211.5, from old  32383.6\n",
      "after gc.collect: from start  32217.9, from old  32385.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:52<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  48275.5, from old  32392.1\n",
      "after model save: from start  48275.5, from old  48449.7\n",
      "after gc.collect: from start  48277.6, from old  48449.7\n",
      "after gc.collect: from start  48283.9, from old  48451.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:55<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  64360.5, from old  48458.1\n",
      "after model save: from start  64360.5, from old  64534.8\n",
      "after gc.collect: from start  64362.6, from old  64534.8\n",
      "after gc.collect: from start  64369.0, from old  64536.8\n",
      "after dev all batch: from start  64370.1, from old  64543.3\n",
      "after dev loop 5593547264\n",
      "after all batch gc.collect(): from start  64372.2, from old  64544.3\n",
      "i_epoch 1 start: from start  64372.2, from old  64546.4\n",
      "epoch_start: 1 5593547264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='131910' class='' max='131910', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [131910/131910 18:34:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:59<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  80464.2, from old  64546.4\n",
      "after model save: from start  80464.2, from old  80638.5\n",
      "after gc.collect: from start  80466.3, from old  80638.5\n",
      "after gc.collect: from start  80472.8, from old  80640.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:56<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  96568.8, from old  80647.0\n",
      "after model save: from start  96568.8, from old  96743.0\n",
      "after gc.collect: from start  96570.8, from old  96743.0\n",
      "after gc.collect: from start  96577.4, from old  96745.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 51:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  112673.4, from old  96751.6\n",
      "after model save: from start  112673.4, from old  112847.6\n",
      "after gc.collect: from start  112675.4, from old  112847.6\n",
      "after gc.collect: from start  112682.3, from old  112849.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14697' class='' max='14697', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14697/14697 50:58<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  128777.6, from old  112856.5\n",
      "after model save: from start  128779.0, from old  128951.9\n",
      "after gc.collect: from start  128781.1, from old  128953.2\n",
      "after gc.collect: from start  128787.8, from old  128955.4\n",
      "after dev all batch: from start  128788.8, from old  128962.0\n",
      "after dev loop 5593544704\n",
      "after all batch gc.collect(): from start  128790.9, from old  128963.1\n",
      "after all folds: from start  128790.9, from old  128965.2\n",
      "after all folds, gc collect: from start  128793.1, from old  128965.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=LENGTH_QUANTILE, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.7561e+04, 3.1961e+04, 1.6081e+04, 8.1280e+03, 5.6660e+03,\n",
       "        3.3400e+03, 2.5220e+03, 1.7370e+03, 1.0410e+03, 9.7000e+02,\n",
       "        4.3400e+02, 7.8100e+02, 3.3300e+02, 0.0000e+00, 2.9600e+02,\n",
       "        2.5600e+02, 0.0000e+00, 2.1700e+02, 1.7800e+02, 0.0000e+00,\n",
       "        0.0000e+00, 1.4200e+02, 0.0000e+00, 0.0000e+00, 1.0500e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.0000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([  1. ,   6.1,  11.2,  16.3,  21.4,  26.5,  31.6,  36.7,  41.8,\n",
       "         46.9,  52. ,  57.1,  62.2,  67.3,  72.4,  77.5,  82.6,  87.7,\n",
       "         92.8,  97.9, 103. , 108.1, 113.2, 118.3, 123.4, 128.5, 133.6,\n",
       "        138.7, 143.8, 148.9, 154. , 159.1, 164.2, 169.3, 174.4, 179.5,\n",
       "        184.6, 189.7, 194.8, 199.9, 205. , 210.1, 215.2, 220.3, 225.4,\n",
       "        230.5, 235.6, 240.7, 245.8, 250.9, 256. ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4VGXax/HvnU6NQALSO9IFjHQSC10FsQIqVkCUGndX3dVddV13V98NTVDAgqCCiAVQuiWhQ+hNkF6FIE16e94/ZnzfLCKZwCSTZH6f68rFzDnPzLkfAr+cOc/MHXPOISIiwSEk0AWIiEj2UeiLiAQRhb6ISBBR6IuIBBGFvohIEFHoi4gEEYW+iEgQUehLnmZmo83s1Sx67u/N7ImseG6RrKLQFxEJIgp9EZEgotCXPMXM6pvZMjP7xcw+AaLS7bvdzFaY2WEzm29mdb3bnzWziRc9z2AzG5KJ44aY2Qtmtt3M9pvZGDOL9u6LMrMPzexn77GXmFkJ775HzGyLt96tZvaAX/4iRH6HQl/yDDOLAL4ExgJFgU+Bu7376gPvAT2BYsAIYLKZRQLjgfZmVsg7NhS4D/g4E4d/xPt1M1AJKAi86d33MBANlPUe+0ngpJkVAIYA7ZxzhYCmwIrMz1zEdwp9yUsaA+HAIOfcWefcRGCJd18PYIRzbpFz7rxz7gPgNNDYObcdWAZ08o69BTjhnFuYiWM/ACQ557Y4544BzwOdzSwMOIsn7Kt4j73UOXfU+7gLQG0zy+ec2+ucW3vl0xfJmEJf8pJSwG73361jt3v/LA884728ctjMDuM58y7l3f8x0MV7uyuZO8v/9djb093fDoQBJfC88pgBjDezPWb2upmFO+eOA/fjOfPfa2Zfm1n1TB5XJFMU+pKX7AVKm5ml21bO++dO4B/OuWvSfeV3zo3z7v8UuMnMyuA5489s6O/B84Ml/XHPAfu8rzpeds7VxHMJ53agG4BzboZzrhVQEvgBGJXJ44pkikJf8pIFeIK2r5mFm9ldQEPvvlHAk2bWyDwKmNltv17Hd86lAd8D7wNbnXPrM3nsccAAM6toZgWB14BPnHPnzOxmM6vjXSs4iudyzwUzK2FmHb3X9k8Dx/Bc7hHJMgp9yTOcc2eAu/AsqB7Ec+nkc+++VKA7nsXVQ8Am77j0PgZakvmzfPAsEo8FUoCtwCmgj3fftcBEPIG/Hkj2jg0BEvG8SjgIJAC9ruDYIj4z/eYsEZHgoTN9EZEg4lPom1lbM9tgZpvM7LlL7C9nZt+Z2XIzW2Vm7dPtq2tmC8xsrZmtNrOoix8vklOZ2bHf+WoR6NpErkSGl3e8i08bgVbALjzve+7inFuXbsxIYLlz7i0zqwlMdc5V8L5HeRnwkHNupZkVAw47585n0XxEROQywnwY0xDY5JzbAmBm44GOwLp0YxxQ2Hs7Gs/CFEBrYJVzbiWAc+7njA4WExPjKlSo4FPxIiLisXTp0gPOudiMxvkS+qXxvMf5V7uARheNeQmYaWZ9gAJ43gEBUA1wZjYDiAXGO+dev/gAZtYDzycmKVeuHKmpqT6UJSIivzKz7RmP8t9CbhdgtHOuDNAeGGtmIXh+qDTH8xH15kAnM7v14gc750Y65+Kcc3GxsRn+oBIRkSvkS+jvxvNx9V+V8W5L73FgAoBzbgGezoYxeF4VpDjnDjjnTgBTgQZXW7SIiFwZX0J/CVDV+0nDCKAzMPmiMTuAWwHMrAae0E/D02+kjpnl9y7qJvDfawEiIpKNMrym7/0YeW88AR4KvOecW2tmrwCpzrnJwDPAKDMbgGdR9xFv06tDZpaE5weHw/Ounq+zajIiInJ5Oe4TuXFxcU4LuSIimWNmS51zcRmN0ydyRUSCiEJfRCSI5JnQP3X2PC9NXsv+o6cCXYqISI6VZ0J/5c7DfLx4By2TkpmQupOctlYhIpIT5JnQb1SpGNP7taD6tYX508RVPPTuYnYePBHoskREcpQ8E/oAlWILMr5HY/5+Z22W7zhE64EpvDd3K+cv6KxfRATyWOgDhIQYDzUuz8zEBBpVKsorX63j3rfn8+O+XwJdmohIwOW50P9V6Wvy8f4jNzLw/uvZcuA4tw2Zy9BvfuTsef0KUhEJXnk29AHMjE71yzA7MYFWtUrwn1kbuWPoXFbvOhLo0kREAiJPh/6vYgpGMqxrA0Y8dAMHj5+h47C5/HPaek6d1e9yEZHgEhSh/6s2ta5lVmIC98WVZUTyFtoNnsOiLRn+XhcRkTwjqEIfIDpfOP+6uy4fPdGIcxcucP/Ihbzw5Wp+OXU20KWJiGS5oAv9XzWrEsOM/vE83rwiHy3aQeuBKXz3w/5AlyUikqWCNvQB8keE8eLtNfmsV1MKRobx6Ogl9B+/nIPHzwS6NBGRLBHUof+rBuWK8FXf5vS9tSpfrdpLq6Rkpqzco1YOIpLnKPS9IsNCSWxVjSl9mlO6SD76jFtO9zFL2acGbiKShyj0L1KjZGE+79WUv7SvwZwf02iZlMz4xTt01i8ieYJC/xLCQkPoHl+JGf3jqVmyMM99vpquoxax/efjgS5NROSqKPQvo0JMAcZ1b8xrneqwevcR2gxK4Z05W9TATURyLYV+BkJCjK6NyjErMZ6mlWN49ev13PXWfDb8pAZuIpL7KPR9VDI6H+8+HMfgzvXYefAEtw+dw6DZGzlzTg3cRCT3UOhngpnRsV5pZg2Ip32dkgya/SN3DJ3Lyp2HA12aiIhPFPpXoFjBSAZ3rs873eI4cvIsnYbP4x9fr+PkGTVwE5GcTaF/FVrWLMHMxHg6NyzHqDlbaTMohfmbDwS6LBGR36XQv0qFo8J5rVMdPu7eCDPoOmoRz3++mqNq4CYiOZBC30+aVo5her94esRX4pMlO2iVlMzsdfsCXZaIyH9R6PtRvohQ/ty+Bl881Ywi+SN4Ykwqfcct5+djpwNdmogIoNDPEteXvYbJvZszoGU1pq3ZS8ukZCat2K1WDiIScAr9LBIRFkK/llX5um8LyhcrQL/xK3jig1T2HjkZ6NJEJIgp9LNYtRKF+KxXU164rQbzNh+gVVIKHy3azgW1chCRAFDoZ4PQEOOJFpWY2T+BumWi+csXa+gyaiFbD6iBm4hkL4V+NipXLD8fPdGIf91Vh3V7jtJ2UAojUzZz7rxaOYhI9lDoZzMzo3PDcsxKTKBF1Vhem/oDd701n/V7jwa6NBEJAgr9ALk2OopR3W7gza712X3oJHcMnUvSrI2cPqdWDiKSdRT6AWRm3F63FLMTE7jj+lIM+eZHbh8yl2U7DgW6NBHJoxT6OUCRAhEMvL8e7z9yI8dOn+Put+bzypR1nDhzLtCliUgeo9DPQW6uXpyZA+J5oFE53pvnaeA2b5MauImI//gU+mbW1sw2mNkmM3vuEvvLmdl3ZrbczFaZWftL7D9mZn/wV+F5VaGocF69sw6f9GhMWEgID7yziGcnruLISTVwE5Grl2Hom1koMAxoB9QEuphZzYuGvQBMcM7VBzoDwy/anwRMu/pyg0ejSsWY1q8FTyZUZuKyXbRKSmbm2p8CXZaI5HK+nOk3BDY557Y4584A44GOF41xQGHv7Whgz687zOxOYCuw9urLDS5R4aE81646Xz7VjGIFI+kxdilPf7yMtF/UwE1ErowvoV8a2Jnu/i7vtvReAh40s13AVKAPgJkVBJ4FXr7cAcysh5mlmllqWlqaj6UHjzplopncuxl/aF2NWWv30WpgMp8v26UGbiKSaf5ayO0CjHbOlQHaA2PNLATPD4OBzrljl3uwc26kcy7OORcXGxvrp5LylvDQEHrfUpWp/ZpTKaYAiRNW8ujoJew+rAZuIuI7X0J/N1A23f0y3m3pPQ5MAHDOLQCigBigEfC6mW0D+gN/NrPeV1lzUKtSvBCfPtmUv91Rk0VbDtI6KZmxC7apgZuI+MSX0F8CVDWzimYWgWehdvJFY3YAtwKYWQ08oZ/mnGvhnKvgnKsADAJec8696bfqg1RoiPFos4rMHBBPg/JFeHHSWjqPXMiWtMu+oBIRyTj0nXPngN7ADGA9nnfprDWzV8ysg3fYM0B3M1sJjAMecbrgnOXKFs3PmMca8sY9dfnhp6O0HTyHt75XAzcR+X2W07I5Li7OpaamBrqMXGf/0VO8OGkNM9buo3bpwvz77rrUKhUd6LJEJJuY2VLnXFxG4/SJ3DyieOEoRjwUx1sPNOCnI6fp8OY83pjxA6fOqoGbiPw/hX4e065OSWYnxnNnvdIM+24ztw2Zw9LtBwNdlojkEAr9POia/BH8577r+eCxhpw6e4F73l7AS5PXcvy0GriJBDuFfh6WUC2WGQPi6da4PB8s2EbrgSmkbNSH30SCmUI/jysYGcbLHWszoWcTIsND6PbeYv7w6UqOnFADN5FgpNAPEjdWKMrUvi146qbKfLF8Ny0HJjN9zd5AlyUi2UyhH0SiwkP5U9vqTHq6GbEFI3nyw2X0+nAp+385FejSRCSbKPSDUO3S0Uzq3Yw/trmOb37YT6ukFD5N3akGbiJBQKEfpMJDQ3j65ipM7duCqsUL8seJq+j23mJ2HjwR6NJEJAsp9INcleIFmdCzCa90rMWy7YdoMyiF0fO2qoGbSB6l0BdCQoxuTSowY0A8cRWK8tKUddw3YgGb9quBm0heo9CX/1OmSH4+ePRG/nPv9fy4/xjtB89h2HebOKsGbiJ5hkJf/ouZcfcNZZidmEDLmsV5Y8YGOr45jzW7jwS6NBHxA4W+XFJsoUiGP3ADbz/YgLRjp+k4bB7/nq4GbiK5nUJfLqtt7ZLMHpDA3Q1K89b3m2k/eA5LtqmBm0hupdCXDEXnD+f1e67nw8cbceb8Be59ewF/nbSGY2rgJpLrKPTFZ82rxjCjfzyPNqvA2IXbaZ2UzHcb9ge6LBHJBIW+ZEqByDD+dkctJj7ZlPyRYTz6/hISP1nBoeNnAl2aiPhAoS9X5IbyRfi6b3P63FKFySv30GpgMl+v2qtWDiI5nEJfrlhkWCjPtL6Oyb2bUzI6H09/vIyeY5ey/6gauInkVAp9uWo1SxXmi6ea8ny76iRvTOPWpGQmLFEDN5GcSKEvfhEWGkLPhMpM69eCGiUL86fPVvHQu2rgJpLTKPTFryrFFmR898a8emdtVuw8TOuBKbw3dyvn1cBNJEdQ6IvfhYQYDzYuz8wB8TSqVJRXvlrHPW/P58d9vwS6NJGgp9CXLFPqmny8/8iNDLq/HtsOHOe2IXMZ8s2PnDmnBm4igaLQlyxlZtxZvzSzEhNoU/takmZtpMObc1m163CgSxMJSgp9yRYxBSMZ2qU+o7rFcejEGe4cNo9/Tl2vBm4i2UyhL9mqVc0SzByQwP03lmVEyhbaDkph4ZafA12WSNBQ6Eu2i84Xzj/vqsvHTzTigoPOIxfyly9W88ups4EuTSTPU+hLwDStEsP0/i14onlFxi3eQeuBKXz7w75AlyWSpyn0JaDyR4Txwu01+axXUwpFhfHY6FT6j1/OQTVwE8kSCn3JEeqXK8JXfVrQ79aqfL16Ly2Tkpm8co9aOYj4mUJfcoyIsBAGtKrGlD7NKVskH33HLaf7mKX8dEQN3ET8RaEvOU71awvz+VPN+Ev7GszdlEarpGTGLd6hs34RP1DoS44UGmJ0j6/E9H7x1CpdmOc/X03XUYvY/vPxQJcmkqsp9CVHqxBTgI+faMxrneqwZvcR2gxK4Z05W9TATeQKKfQlxwsJMbo2KsfMxHiaVY7h1a/Xc9db89nwkxq4iWSWT6FvZm3NbIOZbTKz5y6xv5yZfWdmy81slZm1925vZWZLzWy1989b/D0BCR4lo/PxzsNxDOlSn50HT3D70DkMmr1RDdxEMiHD0DezUGAY0A6oCXQxs5oXDXsBmOCcqw90BoZ7tx8A7nDO1QEeBsb6q3AJTmZGh+tLMTsxgfZ1SjJo9o/cMXQuK3aqgZuIL3w5028IbHLObXHOnQHGAx0vGuOAwt7b0cAeAOfccufcHu/2tUA+M4u8+rIl2BUtEMHgzvV59+E4jpw8y13D5/HqV+s4eUYN3EQux5fQLw3sTHd/l3dbei8BD5rZLmAq0OcSz3M3sMw5d/riHWbWw8xSzSw1LS3Np8JFAG6tUYKZifF0bliOd+Zupc2gFOZvPhDoskRyLH8t5HYBRjvnygDtgbFm9n/PbWa1gH8DPS/1YOfcSOdcnHMuLjY21k8lSbAoHBXOa53qMK57Y0IMuo5axPOfr+KoGriJ/IYvob8bKJvufhnvtvQeByYAOOcWAFFADICZlQG+ALo55zZfbcEiv6dJ5WJM6xdPz/hKfLJkJ62Skpm9Tg3cRNLzJfSXAFXNrKKZReBZqJ180ZgdwK0AZlYDT+inmdk1wNfAc865ef4rW+TS8kWE8nz7Gnz5dDOK5I/giTGp9Bm3nJ+P/eaqokhQyjD0nXPngN7ADGA9nnfprDWzV8ysg3fYM0B3M1sJjAMecZ7PzPcGqgB/NbMV3q/iWTITkXTqlrmGyb2bk9iqGtPXeBq4TVqxW60cJOhZTvtPEBcX51JTUwNdhuQhG/f9wp8mrmLFzsPcUr04r95Zm1LX5At0WSJ+ZWZLnXNxGY3TJ3Ilz6tWohCf9WrKi7fXZMHmn2k9MIUPF27nglo5SBBS6EtQCA0xHm9ekRn947m+bDQvfLmGLqMWsvWAGrhJcFHoS1ApVyw/Hz7eiNfvrsu6vUdpOyiFEcmbOXderRwkOCj0JeiYGffdWJbZiQnEV4vln9N+4K635rN+79FAlyaS5RT6ErRKFI5i5EM3MKxrA/YcPskdQ+eSNHMDp8+plYPkXQp9CWpmxm11SzJrQAIdri/FkG83cduQuSzdfijQpYlkCYW+CFCkQARJ99fj/Udv5MTpc9zz9nxenrKWE2fOBbo0Eb9S6Iukc/N1xZkxIJ4HG5Xn/XnbaD0whbk/qoGb5B0KfZGLFIoK5+931mZCzyaEh4bw4LuL+NPElRw5qQZukvsp9EV+R8OKRZnWrwW9bqrMZ8t20yopmRlrfwp0WSJXRaEvchlR4aE827Y6Xz7VjGIFI+k5dilPf7SMtF/UwE1yJ4W+iA/qlIlmcu9m/LHNdcxat4+WScl8tnSXGrhJrqPQF/FReGgIT99chan9mlOleEGe+XQlj7y/hN2HTwa6NBGfKfRFMqlK8UJ82rMJL91RkyXbDtI6KZkxC7apgZvkCgp9kSsQEmI80szTwK1B+SL8ddJa7h+5gM1pxwJdmshlKfRFrkLZovkZ81hD3rinLht++oV2g+cw/PtNauAmOZZCX+QqmRn3xpVl9jMJ3HJdcV6fvoE7h89j7Z4jgS5N5DcU+iJ+UrxQFG8/dANvPdCAn46cpsOb83hjxg+cOqsGbpJzKPRF/KxdnZLMToynU/3SDPtuM+2HzCF128FAlyUCKPRFssQ1+SP4n3uvZ8xjDTl99gL3jljAS5PXcvy0GrhJYCn0RbJQfLVYZg6I5+EmFfhggaeBW8rGtECXJUFMoS+SxQpEhvFSh1p82rMJkeEhdHtvMX/4dCWHT5wJdGkShBT6ItkkrkJRpvZtwdM3V+aL5btpmZTCtNV7A12WBBmFvkg2igoP5Y9tqjO5dzNKFI6k10fLeHLsUvYfPRXo0iRIKPRFAqBWqWgmPd2MZ9tW59sN+2mZlMynqTvVwE2ynEJfJEDCQkPodVNlpvVrwXXXFuKPE1fR7b3F7Dx4ItClSR6m0BcJsMqxBfmkRxP+3rEWy7Yfos2gFEbP26oGbpIlFPoiOUBIiPFQkwrMGBDPjRWK8tKUddw7YgGb9v8S6NIkj1Hoi+QgZYrkZ/SjN5J03/VsTjtG+8FzGfbdJs6qgZv4iUJfJIcxM+5qUIZZAxJoVasEb8zYQIc357Fmtxq4ydVT6IvkULGFIhnWtQEjHrqBA8dO03HYPP41TQ3c5Ooo9EVyuDa1rmX2gATuaVCGt5M3037wHBZvVQM3uTIKfZFcIDp/OP++py4fPt6IM+cvcN+IBbz45RqOqYGbZJJCXyQXaV41hpkD4nmsWUU+XLSd1knJfLdhf6DLklxEoS+Sy+SPCOOvd9Rk4pNNKRAZxqPvLyHxkxUcOq4GbpIxhb5ILnVD+SJ81bc5fW+pwuSVe2iZlMxXq/aolYNclkJfJBeLDAslsfV1TOnTnFLX5KP3x8vpOXYp+9TATX6HT6FvZm3NbIOZbTKz5y6xv5yZfWdmy81slZm1T7fvee/jNphZG38WLyIeNUoW5ounmvJ8u+okb0yjZVIynyzZobN++Y0MQ9/MQoFhQDugJtDFzGpeNOwFYIJzrj7QGRjufWxN7/1aQFtguPf5RMTPwkJD6JlQmen946lRsjDPfraaB99dxI6f1cBN/p8vZ/oNgU3OuS3OuTPAeKDjRWMcUNh7OxrY473dERjvnDvtnNsKbPI+n4hkkYoxBRjfvTGv3lmblTuP0GZQCu/O3cp5NXATfAv90sDOdPd3ebel9xLwoJntAqYCfTLxWMysh5mlmllqWpp+f6jI1QoJMR5sXJ6ZA+JpUrkYf/9qHXe/NZ+N+9TALdj5ayG3CzDaOVcGaA+MNTOfn9s5N9I5F+eci4uNjfVTSSJS6pp8vPtwHIM712P7z8e5bcgchnzzI2fOqYFbsPIlmHcDZdPdL+Pdlt7jwAQA59wCIAqI8fGxIpKFzIyO9UozOzGBtrVLkjRrIx3enMvKnYcDXZoEgC+hvwSoamYVzSwCz8Ls5IvG7ABuBTCzGnhCP807rrOZRZpZRaAqsNhfxYuI74oVjGRol/qM6hbHoRNn6DR8Hv+cup6TZ9TALZhkGPrOuXNAb2AGsB7Pu3TWmtkrZtbBO+wZoLuZrQTGAY84j7V4XgGsA6YDTzvn9C9MJIBa1SzBrMQE7r+xLCNSttBucAoLt/wc6LIkm1hOex9vXFycS01NDXQZIkFh/qYDPPf5anYcPEHXRuV4rl11CkeFB7osuQJmttQ5F5fROH0iVySINa0Sw4z+8XRvUZHxi3fQOimFb3/YF+iyJAsp9EWCXL6IUP5yW00+f6oZ0fnCeWx0Kv3GL+fnY6cDXZpkAYW+iABQr+w1TOnTnP4tqzJ19V5aDUxh8ko1cMtrFPoi8n8iwkLo37IaX/VpQdmi+ek7bjndx6Ty0xE1cMsrFPoi8hvXXVuIz3s15YXbajB30wFaJSUzbrEauOUFCn0RuaTQEOOJFpWY0T+e2qWjef7z1XQdtYhtB44HujS5Cgp9Ebms8sUK8HH3Rvzrrjqs2X2EtoNTGJWyRQ3ccimFvohkyMzo3LAcsxITaF4lhn9MXc9dw+ex4Sc1cMttFPoi4rNro6MY1S2OoV3qs+vQSW4fOoeBszaqgVsuotAXkUwxM+64vhSzEhO4rU5JBn/zI7cPncMKNXDLFRT6InJFihaIYFDn+rz3SBy/nDrHXcPn8epX6zhx5lygS5PLUOiLyFW5pXoJZg6Ip0vDcrwzdyttB81h/qYDgS5LfodCX0SuWqGocP7RqQ7jezQmxKDrO4t47rNVHDl5NtClyUUU+iLiN40rFWN6/3h6JlRiQupOWg9MZtY6NXDLSRT6IuJXUeGhPN+uBl8+3Ywi+SPoPiaV3h8v44AauOUICn0RyRJ1y1zD5N7NeaZVNWau3UerpGS+XL5brRwCTKEvIlkmIiyEPrdW5eu+zakQU4D+n6zgsdFL2HP4ZKBLC1oKfRHJclVLFGLik0356+01WbjlIK0HpjB24XYuqJVDtlPoi0i2CA0xHmtekZkD4qlX9hpe/HINnUctZKsauGUrhb6IZKuyRfMz9vGGvH53XdbvPUrbQSm8nbyZc+fVyiE7KPRFJNuZGffdWJbZiQkkVIvlX9N+oNPw+azbczTQpeV5Cn0RCZgShaMY8dANDOvagL1HTtLhzbn8Z+YGTp87H+jS8iyFvogElJlxW92SzBqQQId6pRj67SZuGzKXpdsPBbq0PEmhLyI5QpECESTdV4/Rj97IyTPnueft+bw8ZS3HT6uBmz8p9EUkR7npuuLMGBDPQ43L8/68bbQZlMKcH9MCXVaeodAXkRynYGQYr3SszYSeTYgIDeGhdxfzp4krOXJCDdyulkJfRHKshhWLMrVfC3rdVJnPlu2m5cBkpq/5KdBl5WoKfRHJ0aLCQ3m2bXUmPd2M2IKRPPnhUp7+aBlpv6iB25VQ6ItIrlC7dDSTejfjj22uY9b6fbRMSuazpbvUwC2TFPoikmuEh4bw9M1VmNq3BVWKF+SZT1fy8PtL2HXoRKBLyzUU+iKS61QpXpBPezbh5Q61SN12kDYDUxizYJsauPlAoS8iuVJIiPFw0wrM6B9Pg/JF+Ouktdw/cgGb044FurQcTaEvIrla2aL5GfNYQ/7n3uvZuO8Y7QbPYfj3mzirBm6XpNAXkVzPzLjnhjLMSoynZY3ivD59A3cOm8ea3UcCXVqOo9AXkTyjeKEohj9wA28/2IB9R0/Tcdg8Xp/+A6fOqoHbrxT6IpLntK1dkm8SE7irfmmGf7+Z9kPmkLrtYKDLyhEU+iKSJ0XnD+eNe69nzGMNOX32AveOWMDfJq3hWJA3cPMp9M2srZltMLNNZvbcJfYPNLMV3q+NZnY43b7XzWytma03syFmZv6cgIjI5cRXi2XmgHgeblKBMQu302ZgCskbg7eBW4ahb2ahwDCgHVAT6GJmNdOPcc4NcM7Vc87VA4YCn3sf2xRoBtQFagM3Agl+nYGISAYKRIbxUodafNqzCVHhITz83mKembCSwyfOBLq0bOfLmX5DYJNzbotz7gwwHuh4mfFdgHHe2w6IAiKASCAc2Hfl5YqIXLm4CkX5um8Let9chUkrdtMyKYVpq/cGuqxs5UvolwZ2pru/y7vtN8ysPFAR+BbAObcA+A7Y6/2a4Zxbf4nH9TCzVDNLTUsL3pddIpL1osJD+UOb65jUuxnXRkfS66NlPDl2KfuPngp0adnC3wu5nYGJzrnzAGZWBagBlMHzg+IWM2tx8YOccyOdc3HOubjY2Fg/lyQi8lu1SkXz5VPNeLZtdb7dsJ+WSclMSN2Z5xu4+RL6u4Gy6e6X8W67lM78/6Xf1SPjAAAHV0lEQVQdgE7AQufcMefcMWAa0ORKChUR8bew0BB63VSZ6f1aUP3awvxp4iq6vbeYnQfzbgM3X0J/CVDVzCqaWQSeYJ988SAzqw4UARak27wDSDCzMDMLx7OI+5vLOyIigVQptiDjezTm7x1rsWz7IdoMSuH9eVs5nwcbuGUY+s65c0BvYAaewJ7gnFtrZq+YWYd0QzsD491/vzaaCGwGVgMrgZXOuSl+q15ExE9CQoyHmlRgZmICDSsW5eUp67hvxAI27f8l0KX5leW061dxcXEuNTU10GWISBBzzvHlit28PGUdJ06fp++tVeiZUJnw0Jz7eVYzW+qci8toXM6dgYhIgJgZneqXYXZiAq1qleB/Zm7kjqFzWb0r9zdwU+iLiPyOmIKRDOvagBEP3cDB42e4c/g8/jUtdzdwU+iLiGSgTa1rmZWYwD0NyvB28mbaDZ7Doi0/B7qsK6LQFxHxQXS+cP59T10+eqIR5y5c4P6RC3nxyzX8cupsoEvLFIW+iEgmNKsSw4z+8TzevCIfLvI0cPvuh/2BLstnCn0RkUzKHxHGi7fX5LNeTSkQGcajo5cw4JMVHDye8xu4KfRFRK5Qg3JF+Kpvc/reWpUpK/fQKimZr1btydGtHBT6IiJXITIslMRW1ZjSpzmli+Sj98fL6TF2KftyaAM3hb6IiB/UKFmYz3s15c/tq5OyMY2WScl8smRHjjvrV+iLiPhJWGgIPeIrM6N/PDVLFubZz1bzwDuL2PFzzmngptAXEfGzCjEFGNe9Ma91qsOqXUdoMyiFd+ZsyREN3BT6IiJZICTE6NqoHLMS42lSuRivfr2eu9+az8Z9gW3gptAXEclCJaPz8e7DcQzuXI8dB09w25A5DJ79I2fOXQhIPQp9EZEsZmZ0rFeaWQPiaVe7JANnb6TDm3NZufNwttei0BcRySbFCkYypEt93ukWx+ETZ+k0fB6vTV3PyTPZ18BNoS8iks1a1izBzMR4Ojcsx8iULbQbnMKCzdnTwE2hLyISAIWjwnmtUx0+7t4IB3QZtZBXv1qX5cdV6IuIBFDTyjFM7xdPj/hKlC+WP8uPF5blRxARkcvKFxHKn9vXyJZj6UxfRCSIKPRFRIKIQl9EJIgo9EVEgohCX0QkiCj0RUSCiEJfRCSIKPRFRIKI5bRf5WVmacD2q3iKGOCAn8rJDYJtvqA5BwvNOXPKO+diMxqU40L/aplZqnMuLtB1ZJdgmy9ozsFCc84aurwjIhJEFPoiIkEkL4b+yEAXkM2Cbb6gOQcLzTkL5Llr+iIi8vvy4pm+iIj8DoW+iEgQyZWhb2ZtzWyDmW0ys+cusT/SzD7x7l9kZhWyv0r/8mHOiWa2zsxWmdk3ZlY+EHX6U0ZzTjfubjNzZpbr397ny5zN7D7v93qtmX2c3TX6mw//tsuZ2Xdmttz777t9IOr0FzN7z8z2m9ma39lvZjbE+/exyswa+LUA51yu+gJCgc1AJSACWAnUvGjMU8Db3tudgU8CXXc2zPlmIL/3dq9gmLN3XCEgBVgIxAW67mz4PlcFlgNFvPeLB7rubJjzSKCX93ZNYFug677KOccDDYA1v7O/PTANMKAxsMifx8+NZ/oNgU3OuS3OuTPAeKDjRWM6Ah94b08EbjUzy8Ya/S3DOTvnvnPOnfDeXQiUyeYa/c2X7zPA34F/A6eys7gs4sucuwPDnHOHAJxz+7O5Rn/zZc4OKOy9HQ3sycb6/M45lwIcvMyQjsAY57EQuMbMSvrr+Lkx9EsDO9Pd3+XddskxzrlzwBGgWLZUlzV8mXN6j+M5U8jNMpyz92VvWefc19lZWBby5ftcDahmZvPMbKGZtc226rKGL3N+CXjQzHYBU4E+2VNawGT2/3um6Bej5zFm9iAQByQEupasZGYhQBLwSIBLyW5heC7x3ITn1VyKmdVxzh0OaFVZqwsw2jn3HzNrAow1s9rOuQuBLiw3yo1n+ruBsunul/Fuu+QYMwvD85Lw52ypLmv4MmfMrCXwF6CDc+50NtWWVTKacyGgNvC9mW3Dc+1zci5fzPXl+7wLmOycO+uc2wpsxPNDILfyZc6PAxMAnHMLgCg8jcnyKp/+v1+p3Bj6S4CqZlbRzCLwLNROvmjMZOBh7+17gG+dd4Ukl8pwzmZWHxiBJ/Bz+3VeyGDOzrkjzrkY51wF51wFPOsYHZxzqYEp1y98+bf9JZ6zfMwsBs/lni3ZWaSf+TLnHcCtAGZWA0/op2VrldlrMtDN+y6exsAR59xefz15rru845w7Z2a9gRl4Vv7fc86tNbNXgFTn3GTgXTwvATfhWTDpHLiKr56Pc34DKAh86l2z3uGc6xCwoq+Sj3POU3yc8wygtZmtA84Df3TO5dpXsT7O+RlglJkNwLOo+0huPokzs3F4fnDHeNcp/gaEAzjn3sazbtEe2AScAB716/Fz8d+diIhkUm68vCMiIldIoS8iEkQU+iIiQUShLyISRBT6IiJBRKEvIhJEFPoiIkHkfwFRB9EiWQ9WXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
