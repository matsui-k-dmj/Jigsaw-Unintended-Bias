{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASED でやる\n",
    "\n",
    "fold 6 で"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_I_FOLD = 6\n",
    "\n",
    "N_GRAD_POOL = 8\n",
    "\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 5e-6\n",
    "\n",
    "RESULT_PATH = f\"../models/large-CASED-2-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "MAX_BATCH_SIZE = 256\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "\n",
    "BERT_HIDDEN_SIZE = 1024\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-large-cased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "batch_size = 4\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 2\n",
    "\n",
    "VAL_INTERVAL_RATIO = 0.25\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 1\n",
    "\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_validation = int(n_epochs / VAL_INTERVAL_RATIO)\n",
    "n_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190606-100036.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.drop(columns=['n_oov']).values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 321 ms, total: 4.99 s\n",
      "Wall time: 8.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_uncased_large.csv'\n",
    "        \n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    if 'large' in BERT_MODEL_PATH:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_CASED_large.csv'\n",
    "    else:\n",
    "        tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] This is so cool . It ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] Thank you ! ! This would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] This is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] Is this something I ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of loser ##...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] This is so cool . It ' s like , ' would ...\n",
       "1  [CLS] Thank you ! ! This would make my life a ...\n",
       "2  [CLS] This is such an urgent design problem ; ...\n",
       "3  [CLS] Is this something I ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of loser ##..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:15<00:00, 118698.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.9 s, sys: 1.37 s, total: 15.3 s\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], This, is, so, cool, ., It, ', s, like,...\n",
       "1    [[CLS], Thank, you, !, !, This, would, make, m...\n",
       "2    [[CLS], This, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], Is, this, something, I, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at ../bert-cache/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "100%|██████████| 1804874/1804874 [00:32<00:00, 55419.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 s, sys: 1.04 s, total: 32.3 s\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DynamicBucketIterator(object):\n",
    "    def __init__(self, data, label, capacity, pad_token, shuffle, length_quantile, max_batch_size, for_bert):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.pad_token = pad_token\n",
    "        self.capacity = capacity\n",
    "        self.shuffle = shuffle\n",
    "        self.length_quantile = length_quantile\n",
    "        self.for_bert = for_bert\n",
    "        \n",
    "        self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        old_separator_index = 0\n",
    "        self.separator_index_list = [0]\n",
    "        for i_sample in range(len(self.data)):\n",
    "            sample_index = self.index_sorted[i_sample]\n",
    "            sample = self.data[sample_index]\n",
    "            current_batch_size = i_sample - old_separator_index + 1\n",
    "            if min(len(sample), MAX_LEN) * current_batch_size <= self.capacity and current_batch_size <= max_batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                old_separator_index = i_sample\n",
    "                self.separator_index_list.append(i_sample)\n",
    "                \n",
    "        self.separator_index_list.append(len(self.data)) # [0, ..., start_separator_index, end_separator_index, ..., len(data)]\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        self.reset_index()\n",
    "\n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.separator_index_list) - 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        start_index, end_index = self.separator_index_list[i_bucket : i_bucket + 2]\n",
    "        \n",
    "        index_batch = self.index_sorted[start_index : end_index]\n",
    "\n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        \n",
    "        batch_label = self.label[index_batch]\n",
    "        \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        max_len = min([max_len, MAX_LEN])\n",
    "        if max_len == 0:\n",
    "            max_len = 1\n",
    "        \n",
    "        if self.for_bert:\n",
    "            segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "            padded_batch = []\n",
    "            input_mask_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "                input_mask_batch.append(input_mask[:max_len])\n",
    "\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch\n",
    "        \n",
    "        else:\n",
    "            padded_batch = []\n",
    "            for sample in raw_batch_data:\n",
    "                sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "                padded_batch.append(sample[:max_len])\n",
    "\n",
    "            self.i_batch += 1\n",
    "\n",
    "            return padded_batch, batch_label, index_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    model.eval()\n",
    "    val_avg_loss = 0.\n",
    "    epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "    for batch in progress_bar(val_loader):\n",
    "        x_batch = batch[0]\n",
    "        segment_id_batch = batch[1]\n",
    "        input_mask_batch = batch[2]\n",
    "        y_batch = batch[3]\n",
    "        index_batch = batch[4]\n",
    "\n",
    "        y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "        sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "        sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "\n",
    "        x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "    #                 print('x_features', torch.cuda.memory_allocated())\n",
    "    #                 timer.stamp(f'x_features')\n",
    "\n",
    "        y_pred = model(x_features, sentence_feature_batch)\n",
    "\n",
    "    #                print('after_prediction', torch.cuda.memory_allocated())\n",
    "    #                timer.stamp(f'after_prediction')\n",
    "\n",
    "        del x_features\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "        loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "        val_avg_loss += loss.item() / val_index.shape[0]\n",
    "\n",
    "        epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        del y_pred, loss\n",
    "        torch.cuda.empty_cache()\n",
    "    #                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "    timer.stamp(f'after val all batch')\n",
    "\n",
    "    if i_validation == 7:\n",
    "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "            f'seed{i_seed}-fold{i_fold}-epoch{i_validation}.torchModelState'))\n",
    "\n",
    "    timer.stamp(f'after model save')\n",
    "\n",
    "    val_loss_array[i_seed, 0, i_validation] = val_avg_loss\n",
    "\n",
    "\n",
    "    oof_train[i_seed, i_validation, val_index] = epoch_val_pred\n",
    "\n",
    "    gc.collect()\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "\n",
    "    valid_df = train.iloc[val_index]\n",
    "    weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "    auc_array[i_seed, 0, i_validation] = weighted_auc\n",
    "    del valid_df\n",
    "    gc.collect()\n",
    "\n",
    "    timer.stamp(f'after gc.collect')\n",
    "\n",
    "    np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Finished epoch {i_validation} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "         f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "      file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  178.1\n",
      "epoch start: from start  0.2, from old  178.1\n",
      "start fold 6\n",
      "toxic ratio dev: 0.17380766570568085, val: 0.1735093593597412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ../bert-cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpaqayj9h8\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1396596736\n",
      "loaders 1555587072\n",
      "i_epoch 0 start: from start  107.8, from old  178.3\n",
      "epoch_start: 0 1555587072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='135435' class='' max='135435', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [135435/135435 18:48:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  16355.0, from old  285.9\n",
      "after model save: from start  16355.0, from old  16533.1\n",
      "after gc.collect: from start  16357.2, from old  16533.1\n",
      "after gc.collect: from start  16369.5, from old  16535.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:34<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  32658.3, from old  16547.6\n",
      "after model save: from start  32658.3, from old  32836.4\n",
      "after gc.collect: from start  32660.5, from old  32836.4\n",
      "after gc.collect: from start  32667.0, from old  32838.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:35<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  48954.4, from old  32845.1\n",
      "after model save: from start  48954.4, from old  49132.5\n",
      "after gc.collect: from start  48956.6, from old  49132.5\n",
      "after gc.collect: from start  48962.9, from old  49134.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:36<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  65273.0, from old  49141.0\n",
      "after model save: from start  65273.0, from old  65451.1\n",
      "after gc.collect: from start  65275.1, from old  65451.1\n",
      "after gc.collect: from start  65281.5, from old  65453.2\n",
      "after dev all batch: from start  65282.5, from old  65459.5\n",
      "after dev loop 5601147392\n",
      "after all batch gc.collect(): from start  65284.6, from old  65460.6\n",
      "i_epoch 1 start: from start  65284.6, from old  65462.7\n",
      "epoch_start: 1 5601147392\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='135435' class='' max='135435', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [135435/135435 18:44:59<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:31<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  81602.4, from old  65462.7\n",
      "after model save: from start  81602.4, from old  81780.5\n",
      "after gc.collect: from start  81604.5, from old  81780.5\n",
      "after gc.collect: from start  81610.9, from old  81782.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  97854.0, from old  81788.9\n",
      "after model save: from start  97854.0, from old  98032.1\n",
      "after gc.collect: from start  97856.3, from old  98032.1\n",
      "after gc.collect: from start  97862.6, from old  98034.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  114103.1, from old  98040.7\n",
      "after model save: from start  114103.1, from old  114281.2\n",
      "after gc.collect: from start  114105.2, from old  114281.2\n",
      "after gc.collect: from start  114111.5, from old  114283.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='15048' class='' max='15048', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [15048/15048 51:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  130340.2, from old  114289.6\n",
      "after model save: from start  130342.2, from old  130518.3\n",
      "after gc.collect: from start  130344.4, from old  130520.3\n",
      "after gc.collect: from start  130350.8, from old  130522.4\n",
      "after dev all batch: from start  130352.0, from old  130528.9\n",
      "after dev loop 5601146880\n",
      "after all batch gc.collect(): from start  130354.1, from old  130530.0\n",
      "after all folds: from start  130354.1, from old  130532.2\n",
      "after all folds, gc collect: from start  130356.3, from old  130532.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_len_list = []\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_validation))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_validation, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):        \n",
    "        if i_fold != TRAIN_I_FOLD:\n",
    "            continue\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = DynamicBucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=True,\n",
    "                                    length_quantile=0.95, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        val_loader = DynamicBucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    capacity=MAX_LEN*batch_size, pad_token=0, shuffle=False,\n",
    "                                    length_quantile=1, max_batch_size=MAX_BATCH_SIZE, for_bert=True)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        i_validation = 0\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=MIN_LR, max_lr=MAX_LR,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "\n",
    "                if i_fold == 0 and i_epoch == 0:\n",
    "                    batch_len_list.append(len(x_batch))\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                if i_batch % N_GRAD_POOL == 0 or i_batch + 1 == len(dev_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "#                 print('optimizer.step()', torch.cuda.memory_allocated())\n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "\n",
    "                if ((i_batch+1) / len(dev_loader)) + i_epoch >= (i_validation+1) * VAL_INTERVAL_RATIO:\n",
    "                    validate()\n",
    "                    model.train()\n",
    "                    i_validation += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, 0, i_epoch] = dev_avg_loss\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(batch_len_list, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3c50ff23e48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loss_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mN_FOLDS_TRAINED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "                                                                                                            \n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)                                                                                              \n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
