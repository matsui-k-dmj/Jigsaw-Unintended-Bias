{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNCASEDでやる\n",
    "\n",
    "foldを固定して、デフォルトのdrop0.1を学習して、0.3と比較する\n",
    "\n",
    "batch sizeが小さいので、buckets は shuffleしたほうがいいでしょう\n",
    "\n",
    "Fine tuniningする！\n",
    "dropout 0.1する\n",
    "\n",
    "Tokenize済みのtrainを使う\n",
    "\n",
    "sentence_dfやる, warm up\n",
    "\n",
    "\n",
    "# Property\n",
    "- LSTM\n",
    "- no annealing\n",
    "- aux\n",
    "- Subgroup negative\n",
    "\n",
    "## pytorch-pretrained-BERT\n",
    "- import pytorch-pretrained-bert from source in dataset\n",
    "\n",
    "the source is cloned from [huggingface/pytorch\\-pretrained\\-BERT: 📖The Big\\-&\\-Extending\\-Repository\\-of\\-Transformers: Pretrained PyTorch models for Google's BERT, OpenAI GPT & GPT\\-2, Google/CMU Transformer\\-XL\\.](https://github.com/huggingface/pytorch-pretrained-BERT)\n",
    "\n",
    "- convert tf checkpoints to pytorch model\n",
    "\n",
    "\n",
    "- feature extraction with BERT like [huggingface/pytorch\\-pretrained\\-BERT: 📖The Big\\-&\\-Extending\\-Repository\\-of\\-Transformers: Pretrained PyTorch models for Google's BERT, OpenAI GPT & GPT\\-2, Google/CMU Transformer\\-XL\\.](https://github.com/huggingface/pytorch-pretrained-BERT)\n",
    "\n",
    "This kernel is based off of [Import functions from Kaggle script](https://www.kaggle.com/rtatman/import-functions-from-kaggle-script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_seeds = 1\n",
    "n_splits = 10\n",
    "n_epochs = 3\n",
    "\n",
    "RESULT_TXT = f\"bert-{datetime.now().strftime('%Y%m%d-%H%M%S')}.txt\"\n",
    "RESULT_PATH = \"../models/fine-tune-bert-uncased-drop0.1\"\n",
    "\n",
    "OUT_DROPOUT = 0.1\n",
    "\n",
    "TRAIN_ON_N_SPLITS = 2\n",
    "\n",
    "SUBGROUP_NEGATIVE_WEIGHT_COEF = 1\n",
    "\n",
    "BERT_HIDDEN_SIZE = 768\n",
    "\n",
    "BERT_MODEL_PATH = 'bert-base-uncased'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    DEBUG_DATA_SIZE = 1000\n",
    "    n_seeds = 1\n",
    "    n_splits = 10\n",
    "    n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-20190506-060401.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencefeaturesoov', 'crawl_emb_nocomp.pickle', 'jigsaw-unintended-bias-in-toxicity-classification', 'crawl_emb_processed_lz4.joblib', 'x-train-tokenized', 'crawl_emb_nocomp.joblib', 'crawl_emb_processed.joblib', 'bert-pretrained-models', 'fasttext-crawl-300d-2m', 'jigsaw-x-train-bert-tokenized', 'glove840b300dtxt', 'roov-crawl.pickle']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from contextlib import contextmanager\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from keras.preprocessing import text, sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9G\n",
    "\n",
    "if DEBUG:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "y_train = np.where(train['target'] >= 0.5, 1, 0)\n",
    "y_aux_train = train[['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv', nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    sentence_df = pd.read_csv('../input/sentencefeaturesoov/sentence_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          26        3        24     1      2         6       0      0   \n",
       "1          29        3        27     3      0         6       0      0   \n",
       "2          19        2        19     1      0         3       0      0   \n",
       "3          19        3        17     0      2         2       0      0   \n",
       "4           9        0         9     0      0         1       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.115385        0.923077    0.038462     0.076923        0.230769   \n",
       "1       0.103448        0.931034    0.103448     0.000000        0.206897   \n",
       "2       0.105263        1.000000    0.052632     0.000000        0.157895   \n",
       "3       0.157895        0.894737    0.000000     0.105263        0.105263   \n",
       "4       0.000000        1.000000    0.000000     0.000000        0.111111   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0          0.0  \n",
       "1           0.0          0.0  \n",
       "2           0.0          0.0  \n",
       "3           0.0          0.0  \n",
       "4           0.0          0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_feature_mat = sentence_df.values\n",
    "del sentence_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "subgroup_bool_train = train[identity_columns].fillna(0)>=0.5\n",
    "toxic_bool_train = train[TOXICITY_COLUMN].fillna(0)>=0.5\n",
    "subgroup_negative_mask = subgroup_bool_train.values.sum(axis=1).astype(bool) & ~toxic_bool_train\n",
    "\n",
    "sample_weight = np.ones((y_train.shape[0],))\n",
    "sample_weight += SUBGROUP_NEGATIVE_WEIGHT_COEF * subgroup_negative_mask\n",
    "\n",
    "del subgroup_bool_train, toxic_bool_train, subgroup_negative_mask\n",
    "gc.collect()\n",
    "\n",
    "y_train_torch = torch.tensor(np.concatenate([y_train[:, np.newaxis], y_aux_train, sample_weight[:, np.newaxis]], axis=1), dtype=torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 s, sys: 388 ms, total: 5.44 s\n",
      "Wall time: 8.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if BERT_DO_LOWER:\n",
    "    tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized.csv'\n",
    "else:\n",
    "    tokenized_path = '../input/jigsaw-x-train-bert-tokenized/x_train_tockenized_cased.csv'\n",
    "    \n",
    "\n",
    "if DEBUG:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None, nrows=DEBUG_DATA_SIZE)\n",
    "else:\n",
    "    df_x_tokenized = pd.read_csv(tokenized_path,\n",
    "                                 header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] this is so cool . it ' s like , ' would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] thank you ! ! this would make my life a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] this is such an urgent design problem ; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] is this something i ' ll be able to inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] ha ##ha you guys are a bunch of losers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [CLS] this is so cool . it ' s like , ' would ...\n",
       "1  [CLS] thank you ! ! this would make my life a ...\n",
       "2  [CLS] this is such an urgent design problem ; ...\n",
       "3  [CLS] is this something i ' ll be able to inst...\n",
       "4  [CLS] ha ##ha you guys are a bunch of losers ...."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804874/1804874 [00:13<00:00, 134889.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 1.31 s, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train_tockenized = df_x_tokenized[0].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_x_tokenized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[CLS], this, is, so, cool, ., it, ', s, like,...\n",
       "1    [[CLS], thank, you, !, !, this, would, make, m...\n",
       "2    [[CLS], this, is, such, an, urgent, design, pr...\n",
       "3    [[CLS], is, this, something, i, ', ll, be, abl...\n",
       "4    [[CLS], ha, ##ha, you, guys, are, a, bunch, of...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tockenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpdlvdz2g3\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 401835.81B/s]\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpdlvdz2g3 to cache at ../bert-cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for ../bert-cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpdlvdz2g3\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../bert-cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "100%|██████████| 1804874/1804874 [00:27<00:00, 66105.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 947 ms, total: 26.9 s\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=BERT_DO_LOWER, cache_dir='../bert-cache')\n",
    "x_train_indexed = x_train_tockenized.progress_apply(lambda x: tokenizer.convert_tokens_to_ids(x[:MAX_LEN]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_tockenized, tokenizer\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BucketIterator(object):\n",
    "    def __init__(self, data, label, batch_size, pad_token, shuffle=True,\n",
    "                length_quantile=0.95):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_token = pad_token\n",
    "        self.length_quantile = length_quantile\n",
    "        # i_batch と i_bucketを変換するindex, shuffleならpermuteする\n",
    "        self.bucket_index = range(self.__len__())\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            self.index_sorted = sorted(range(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "        \n",
    "        self.reset_index()\n",
    "        \n",
    "    def reset_index(self):\n",
    "        self.i_batch = 0\n",
    "        \n",
    "        if self.shuffle:\n",
    "            self.index_sorted = sorted(np.random.permutation(len(self.data)), key=lambda i: len(self.data[i]))\n",
    "            self.bucket_index = np.random.permutation(self.__len__())\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.batch_size + 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            i_bucket = self.bucket_index[self.i_batch]\n",
    "        except IndexError as e:\n",
    "            self.reset_index()\n",
    "            raise StopIteration\n",
    "            \n",
    "        index_batch = self.index_sorted[i_bucket * self.batch_size:\n",
    "                                        (i_bucket + 1) * self.batch_size]\n",
    "                                   \n",
    "        raw_batch_data = [self.data[i] for i in index_batch]\n",
    "        batch_label = self.label[index_batch]\n",
    "            \n",
    "        max_len = int(math.ceil(np.quantile([len(x) for x in raw_batch_data], self.length_quantile)))\n",
    "        segment_id_batch = np.zeros((len(raw_batch_data), max_len))\n",
    "        padded_batch = []\n",
    "        input_mask_batch = []\n",
    "        for sample in raw_batch_data:\n",
    "            input_mask = [1] * len(sample) + [0] * (max_len - len(sample))\n",
    "            input_mask_batch.append(input_mask[:max_len])\n",
    "            \n",
    "            sample = sample + [self.pad_token for _ in range(max_len - len(sample))]\n",
    "            padded_batch.append(sample[:max_len])\n",
    "            \n",
    "        self.i_batch += 1\n",
    "            \n",
    "        return padded_batch, segment_id_batch, input_mask_batch, batch_label, index_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(BERT_MODEL_PATH, cache_dir='../bert-cache')\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, x_features, sentence_features):\n",
    "        \n",
    "        _, bert_output = self.bert_model(*x_features, output_all_encoded_layers=False)\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "OOF_TRAIN_COL = 'oof_train'\n",
    "SUBGROUP_AUC_COL = 'subgroup_auc'\n",
    "BPSN_AUC_COL = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC_COL = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "from sklearn import metrics\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup_col, label_col, oof_col):\n",
    "    subgroup_examples = df[df[subgroup_col]]\n",
    "    return compute_auc(subgroup_examples[label_col], subgroup_examples[oof_col])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup_col] & ~df[label_col]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup_col] & df[label_col]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup_col, label_col, oof_col):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup_col] & df[label_col]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup_col] & ~df[label_col]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label_col], examples[oof_col])\n",
    "\n",
    "def compute_bias_metrics_for_model(df,\n",
    "                                   subgroup_list,\n",
    "                                   oof_col,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    record_list = []\n",
    "    for subgroup in subgroup_list:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(df[df[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC_COL] = compute_subgroup_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BPSN_AUC_COL] = compute_bpsn_auc(df, subgroup, label_col, oof_col)\n",
    "        record[BNSP_AUC_COL] = compute_bnsp_auc(df, subgroup, label_col, oof_col)\n",
    "        record_list.append(record)\n",
    "    return pd.DataFrame(record_list).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "# Convert taget and identity columns to booleans\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in ['target'] + identity_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC_COL], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC_COL], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n",
    "\n",
    "def get_various_auc(valid_df, y_pred):\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    valid_df.loc[:, OOF_TRAIN_COL] = y_pred\n",
    "    valid_df = convert_dataframe_to_bool(valid_df.fillna(0))\n",
    "    bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, OOF_TRAIN_COL, TOXICITY_COLUMN)\n",
    "    overall_auc = calculate_overall_auc(valid_df, OOF_TRAIN_COL)\n",
    "    return get_final_metric(bias_metrics_df, overall_auc), overall_auc, bias_metrics_df\n",
    "\n",
    "def adjust_lr(optimizer, i_batch, min_lr, max_lr, n_batch_all, warm_up_batch_ratio):\n",
    "    n_batch_warmed = int(n_batch_all * warm_up_batch_ratio)\n",
    "    if i_batch > n_batch_warmed:\n",
    "        optimizer.param_groups[0]['lr'] = max_lr\n",
    "    else:\n",
    "        optimizer.param_groups[0]['lr'] = (max_lr - min_lr) / n_batch_warmed * i_batch + min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.clock()\n",
    "        self.old_time = time.clock()\n",
    "        print('start mearsure elapsed times')\n",
    "        \n",
    "    def stamp(self, comment):\n",
    "        print(comment + f': from start {time.clock() - self.start_time: .1f}, from old {self.old_time - - self.start_time: .1f}')\n",
    "        self.old_time = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57802752"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start mearsure elapsed times\n",
      "start seed 0\n",
      "seed start: from start  0.0, from old  163.5\n",
      "epoch start: from start  0.2, from old  163.6\n",
      "start fold 1\n",
      "toxic ratio dev: 0.17373737692832947, val: 0.1741420030593872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpxwszav88\n",
      "100%|██████████| 407873900/407873900 [05:19<00:00, 1276076.49B/s]\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpxwszav88 to cache at ../bert-cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for ../bert-cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpxwszav88\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../bert-cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file ../bert-cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpmd6qziku\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 498465792\n",
      "loaders 664665088\n",
      "i_epoch 0 start: from start  109.8, from old  163.7\n",
      "epoch_start: 0 664665088\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='101525' class='' max='101525', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101525/101525 4:56:26<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dev all batch: from start  17604.8, from old  273.3\n",
      "after dev loop 1989224960\n",
      "after all batch gc.collect(): from start  17607.0, from old  17768.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11281' class='' max='11281', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [11281/11281 13:19<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  18383.0, from old  17770.5\n",
      "after model save: from start  18383.3, from old  18546.6\n",
      "after gc.collect: from start  18385.4, from old  18546.9\n",
      "after gc.collect: from start  18398.1, from old  18548.9\n",
      "i_epoch 1 start: from start  18398.1, from old  18561.6\n",
      "epoch_start: 1 1989224448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='101525' class='' max='101525', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101525/101525 4:56:38<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dev all batch: from start  35902.0, from old  18561.7\n",
      "after dev loop 1989224960\n",
      "after all batch gc.collect(): from start  35904.1, from old  36065.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11281' class='' max='11281', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [11281/11281 13:19<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  36681.0, from old  36067.6\n",
      "after model save: from start  36681.5, from old  36844.5\n",
      "after gc.collect: from start  36683.7, from old  36845.1\n",
      "after gc.collect: from start  36690.7, from old  36847.3\n",
      "i_epoch 2 start: from start  36690.7, from old  36854.3\n",
      "epoch_start: 2 1989224448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='101525' class='' max='101525', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [101525/101525 4:56:39<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dev all batch: from start  54200.4, from old  36854.3\n",
      "after dev loop 1989224960\n",
      "after all batch gc.collect(): from start  54202.6, from old  54363.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11281' class='' max='11281', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [11281/11281 13:19<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after val all batch: from start  54979.4, from old  54366.1\n",
      "after model save: from start  54980.1, from old  55143.0\n",
      "after gc.collect: from start  54982.4, from old  55143.6\n",
      "after gc.collect: from start  54989.7, from old  55145.9\n",
      "after all folds: from start  54989.7, from old  55153.2\n",
      "after all folds, gc collect: from start  54992.1, from old  55153.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "timer = ElapsedTimer()\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "dev_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "val_loss_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "\n",
    "auc_array = np.zeros((n_seeds, TRAIN_ON_N_SPLITS, n_epochs))\n",
    "\n",
    "oof_train = np.zeros((n_seeds, n_epochs, len(x_train_indexed)))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_seed in range(n_seeds):\n",
    "    print(f'start seed {i_seed}')\n",
    "    timer.stamp('seed start')\n",
    "    fold_dev_loss_list = []\n",
    "    fold_val_loss_list = []\n",
    "    \n",
    "    \n",
    "    for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "        if i_fold == 0:\n",
    "            continue\n",
    "        \n",
    "        if i_fold >= TRAIN_ON_N_SPLITS:\n",
    "            break\n",
    "        timer.stamp('epoch start')\n",
    "            \n",
    "        \n",
    "        print(f'start fold {i_fold}')\n",
    "        print(f'toxic ratio dev: {y_train_torch[dev_index].mean().item()}, val: {y_train_torch[val_index].mean().item()}')\n",
    "        \n",
    "        # Load pre-trained model (weights)\n",
    "        model = NeuralNet(y_aux_train.shape[-1], sentence_feature_mat.shape[-1])\n",
    "        model.cuda()\n",
    "        print('model', torch.cuda.memory_allocated())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        dev_sentence_feature_mat = scaler.fit_transform(sentence_feature_mat[dev_index])\n",
    "        val_sentence_feature_mat = scaler.transform(sentence_feature_mat[val_index])\n",
    "        \n",
    "        joblib.dump(scaler, os.path.join(RESULT_PATH, f'scaler-seed{i_seed}-fold{i_fold}.joblib'))\n",
    "\n",
    "        dev_loader = BucketIterator([x_train_indexed[i] for i in dev_index],\n",
    "                                    torch.cat([y_train_torch[dev_index],\n",
    "                                               torch.tensor(dev_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    batch_size=batch_size, pad_token=0, shuffle=True)\n",
    "        val_loader = BucketIterator([x_train_indexed[i] for i in val_index],\n",
    "                                    torch.cat([y_train_torch[val_index],\n",
    "                                               torch.tensor(val_sentence_feature_mat, dtype=torch.float32).cuda()], dim=1),\n",
    "                                    batch_size=batch_size, pad_token=0, shuffle=False)\n",
    "        \n",
    "        print('loaders', torch.cuda.memory_allocated())\n",
    "        \n",
    "        \n",
    "        all_test_preds = []\n",
    "        dev_loss_list = []\n",
    "        val_loss_list = []\n",
    "\n",
    "        for i_epoch in range(n_epochs):\n",
    "            timer.stamp(f'i_epoch {i_epoch} start')\n",
    "            \n",
    "            print(f'epoch_start: {i_epoch}', torch.cuda.memory_allocated())\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.train()\n",
    "            dev_avg_loss = 0.\n",
    "            for i_batch, batch in enumerate(progress_bar(dev_loader)):\n",
    "                if i_epoch == 0:\n",
    "                    adjust_lr(optimizer, i_batch, min_lr=1e-6, max_lr=1e-5,\n",
    "                              n_batch_all=len(dev_loader), warm_up_batch_ratio=0.1)\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                \n",
    "                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "#                 print('loss.backward()', torch.cuda.memory_allocated())\n",
    "\n",
    "                optimizer.step()\n",
    "                dev_avg_loss += loss.item() / dev_index.shape[0]\n",
    "                \n",
    "                \n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del y_pred', torch.cuda.memory_allocated())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            timer.stamp(f'after dev all batch')\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print('after dev loop', torch.cuda.memory_allocated())\n",
    "            timer.stamp(f'after all batch gc.collect()')\n",
    "            \n",
    "            dev_loss_array[i_seed, i_fold, i_epoch] = dev_avg_loss\n",
    "\n",
    "            model.eval()\n",
    "            val_avg_loss = 0.\n",
    "            epoch_val_pred = np.zeros(val_index.shape[0])\n",
    "            for batch in progress_bar(val_loader):\n",
    "                x_batch = batch[0]\n",
    "                segment_id_batch = batch[1]\n",
    "                input_mask_batch = batch[2]\n",
    "                y_batch = batch[3]\n",
    "                index_batch = batch[4]\n",
    "                \n",
    "                y_true_batch = y_batch[:, :1+y_aux_train.shape[-1]]\n",
    "                sample_weight_batch = y_batch[:, 1+y_aux_train.shape[-1]]\n",
    "                sentence_feature_batch = y_batch[:, -sentence_feature_mat.shape[-1]:]\n",
    "                \n",
    "                x_features = [torch.tensor(feature, dtype=torch.long).cuda() for feature in [x_batch, segment_id_batch, input_mask_batch]]\n",
    "#                 print('x_features', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'x_features')\n",
    "                \n",
    "                y_pred = model(x_features, sentence_feature_batch)\n",
    "                \n",
    "#                 print('after_prediction', torch.cuda.memory_allocated())\n",
    "#                 timer.stamp(f'after_prediction')\n",
    "                \n",
    "                del x_features\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('torch.cuda.empty_cache()', torch.cuda.memory_allocated())\n",
    "                                \n",
    "                loss_fn = nn.BCEWithLogitsLoss(sample_weight_batch[:, None], reduction='sum')\n",
    "                loss = loss_fn(y_pred, y_true_batch) # last one is a sample weight\n",
    "\n",
    "                val_avg_loss += loss.item() / val_index.shape[0]\n",
    "                \n",
    "                epoch_val_pred[index_batch] = sigmoid(y_pred[:, 0].detach().cpu().numpy())\n",
    "                \n",
    "                del y_pred, loss\n",
    "                torch.cuda.empty_cache()\n",
    "#                 print('del x_cat, y_pred', torch.cuda.memory_allocated())\n",
    "            \n",
    "            timer.stamp(f'after val all batch')\n",
    "\n",
    "            torch.save(model.state_dict(), os.path.join(RESULT_PATH, \n",
    "                f'seed{i_seed}-fold{i_fold}-epoch{i_epoch}.torchModelState'))\n",
    "            \n",
    "            timer.stamp(f'after model save')\n",
    "\n",
    "            val_loss_array[i_seed, i_fold, i_epoch] = val_avg_loss\n",
    "            \n",
    "            \n",
    "            oof_train[i_seed, i_epoch, val_index] = epoch_val_pred\n",
    "\n",
    "            gc.collect()\n",
    "            timer.stamp(f'after gc.collect')\n",
    "\n",
    "            \n",
    "            valid_df = train.iloc[val_index]\n",
    "            weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, epoch_val_pred)\n",
    "            auc_array[i_seed, i_fold, i_epoch] = weighted_auc\n",
    "            del valid_df\n",
    "            gc.collect()\n",
    "            \n",
    "            timer.stamp(f'after gc.collect')\n",
    "\n",
    "            np.save(os.path.join(RESULT_PATH, 'oof_train.npy'), oof_train)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f'Finished epoch {i_epoch} in {elapsed_time: .0f}, dev_loss: {dev_avg_loss:.4f}, val_loss: {val_avg_loss:.4f}' + \\\n",
    "                     f', weighted_auc: {weighted_auc}, overall_auc: {overall_auc} ',\n",
    "                  file=open(os.path.join(RESULT_PATH, RESULT_TXT), 'a'))\n",
    "        \n",
    "        timer.stamp(f'after all folds')\n",
    "        \n",
    "        fold_dev_loss_list.append(dev_loss_list)\n",
    "        fold_val_loss_list.append(val_loss_list)\n",
    "        del dev_loader, val_loader, model, epoch_val_pred, optimizer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        timer.stamp(f'after all folds, gc collect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_loss_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_FOLDS_TRAINED = 2\n",
    "plt.figure()\n",
    "plt.title('dev_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for dev_loss in dev_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), dev_loss)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('val_loss')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in val_loss_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title('val_auc')\n",
    "for i_seed in range(n_seeds):\n",
    "    for loss in auc_array[i_seed, :N_FOLDS_TRAINED]:\n",
    "        plt.plot(range(n_epochs), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index_list = []\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=1999)\n",
    "for i_fold, (dev_index, val_index) in enumerate(kf.split(x_train_indexed)):\n",
    "    if i_fold >= 2:\n",
    "        break\n",
    "    \n",
    "    valid_index_list.append(val_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train = np.load(os.path.join(RESULT_PATH, 'oof_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train += np.load(os.path.join(RESULT_PATH, 'oof_train_fold0.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 1804874)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last 3\n",
      "weighted auc: mean:  0.9415, std:  0.0000\n",
      "overall auc: mean:  0.9729, std:  0.0000\n",
      "\n",
      "last 2\n",
      "weighted auc: mean:  0.9400, std:  0.0000\n",
      "overall auc: mean:  0.9720, std:  0.0000\n",
      "\n",
      "last 1\n",
      "weighted auc: mean:  0.9355, std:  0.0000\n",
      "overall auc: mean:  0.9699, std:  0.0000\n",
      "\n",
      " Searched for best start epoch.\n",
      "Best start epoch: 0, Best weighted auc: 0.9415273703455507\n",
      "\n",
      "last 3\n",
      "weighted auc: mean:  0.9382, std:  0.0000\n",
      "overall auc: mean:  0.9715, std:  0.0000\n",
      "\n",
      "last 3\n",
      "weighted auc: mean:  0.9414, std:  0.0000\n",
      "overall auc: mean:  0.9727, std:  0.0000\n",
      "\n",
      " Searched for best end epoch.\n",
      "Best end epoch: 2, Best weighted auc: 0.9414150952729043\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    valid_df = train.iloc[:DEBUG_DATA_SIZE]\n",
    "else:\n",
    "    valid_df = train\n",
    "from IPython.display import display\n",
    "\n",
    "valid_index = np.concatenate(valid_index_list)\n",
    "\n",
    "valid_df = valid_df.iloc[valid_index]\n",
    "oof_train = oof_train[:, :, valid_index]\n",
    "\n",
    "def last_n_ensemble(start_epoch, end_epoch=n_epochs):\n",
    "    print()\n",
    "    print(f'last {n_epochs - start_epoch}')\n",
    "    weighted_auc_list = []\n",
    "    for oof_seed in oof_train:\n",
    "        oof_last = np.mean(oof_seed[start_epoch:end_epoch], axis=0)\n",
    "        weighted_auc, overall_auc, bias_df = get_various_auc(valid_df, oof_last)\n",
    "        weighted_auc_list.append(weighted_auc)\n",
    "    print(f'weighted auc: mean: {np.mean(weighted_auc_list): 0.4f}, std: {np.std(weighted_auc_list): 0.4f}')\n",
    "    print(f'overall auc: mean: {np.mean(overall_auc): 0.4f}, std: {np.std(overall_auc): 0.4f}')\n",
    "    return np.mean(weighted_auc_list)\n",
    "\n",
    "best_auc = 0\n",
    "for start_epoch in range(n_epochs):\n",
    "    w_auc = last_n_ensemble(start_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_epoch = start_epoch\n",
    "    gc.collect()\n",
    "\n",
    "print('\\n Searched for best start epoch.')\n",
    "print(f'Best start epoch: {best_epoch}, Best weighted auc: {best_auc}')\n",
    "\n",
    "best_start_epoch = best_epoch\n",
    "best_auc = 0\n",
    "best_end_epoch = best_start_epoch + 1\n",
    "for end_epoch in range(best_start_epoch+1, n_epochs):\n",
    "    w_auc = last_n_ensemble(best_start_epoch, end_epoch)\n",
    "    if w_auc > best_auc:\n",
    "        best_auc = w_auc\n",
    "        best_end_epoch = end_epoch\n",
    "    gc.collect()\n",
    "    \n",
    "print('\\n Searched for best end epoch.')\n",
    "print(f'Best end epoch: {best_end_epoch}, Best weighted auc: {best_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
